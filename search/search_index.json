{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v040-2024-08-28","title":"v0.4.0 (2024-08-28)","text":""},{"location":"changelog/#breaking-change","title":"BREAKING CHANGE","text":"<ul> <li>some module and function signature changes (gradient and mcmc)</li> </ul>"},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>migrate to comply with copier template</li> <li>link with copier-numpy template</li> </ul>"},{"location":"changelog/#v030-2024-02-19","title":"v0.3.0 (2024-02-19)","text":""},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>adding sobol analysis</li> </ul>"},{"location":"changelog/#v020-2024-02-09","title":"v0.2.0 (2024-02-09)","text":""},{"location":"changelog/#feat_2","title":"Feat","text":"<ul> <li>mcmc enhancements</li> </ul>"},{"location":"changelog/#v010-2024-01-27","title":"v0.1.0 (2024-01-27)","text":""},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing-to-uqtils","title":"Contributing to uqtils","text":"<p>You might be here if you want to:</p> <ul> <li>Report a bug</li> <li>Discuss the current state of the code</li> <li>Submit a fix</li> <li>Propose a new feature</li> <li>Write unit tests</li> <li>Add to the documentation.</li> </ul> <p>We use Github to host code and documentation, to track issues and feature requests, and to accept pull requests.</p>"},{"location":"contributing/#submitting-pull-requests","title":"Submitting pull requests","text":"<p>Pull requests are the best way to propose changes to the codebase (bug fixes, new features, docs, etc.)</p> <ol> <li>Fork the repo and create a branch from <code>main</code>.</li> <li>If you are adding a feature or making major changes, first create the issue in Github.</li> <li>If you've added code that should be tested, add to <code>/tests</code>.</li> <li>If you've made major changes, update the <code>/docs</code>.</li> <li>Ensure the test suite passes (<code>pdm run test</code>).</li> <li>Follow Conventional commits guidelines when adding a commit message.</li> <li>Ensure all <code>pre-commit</code> checks pass. Pro tip: use <code>pdm lint</code> to help.</li> <li>Issue the pull request!</li> </ol> <p>Use pdm to set up your development environment. An example contribution workflow is shown here:</p> <pre><code># Fork the repo on Github\ngit clone https://github.com/&lt;your-user-name&gt;/uqtils.git\ncd uqtils\npdm install\ngit checkout -b &lt;your-branch-name&gt;\n\n# Make local changes\n\npdm run test  # make sure tests pass\ngit add -A\ngit commit -m \"fix: adding a bugfix\"\ngit push -u origin &lt;your-branch-name&gt;\n\n# Go to Github and \"Compare &amp; Pull Request\" on your fork\n# For your PR to be merged:\n  # squash all your commits on your branch (interactively in an IDE most likely)\n  # rebase to the top of origin/main to include new changes from others\n\ngit fetch\ngit rebase -i main your-branch  # for example\n\n# Resolve any conflicts\n# Your history now looks something like this:\n#              o your-branch\n#             /\n# ---o---o---o main\n\n# You can delete the branch and fork when your PR has been merged!\n</code></pre> <p>You can also find a good tutorial here.</p>"},{"location":"contributing/#report-bugs-using-issues","title":"Report bugs using issues","text":"<p>Open a new issue and describe your problem using the template. Provide screenshots where possible and example log files. Add labels to help categorize and describe your issue.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the GPL-3.0 license.</p>"},{"location":"coverage/","title":"Coverage report","text":""},{"location":"how-to-guides/","title":"How-to Guides","text":""},{"location":"how-to-guides/#format-a-matplotlib-figure","title":"Format a <code>matplotlib</code> figure","text":"<p>Final result:</p> <p></p> <p>Steps:</p> <ol> <li>Install the STIX fonts.</li> <li> <p>Import the <code>uqtils.default</code> style template:</p> <pre><code>import matplotlib.pyplot as plt\n\nplt.style.use('uqtils.default')  # Globally in the file, or...\n\nwith plt.style.context('uqtils.default'):\n    plt.plot(...)\n</code></pre> </li> <li> <p>Use the <code>ax_default</code> convenience method for adding a legend and axis labels:</p> <pre><code>fig, ax = plt.subplots()\nh1, = ax.plot(x, y, '-r')\n...\nleg = {'handles': [h1, ...], 'labels': [..., 'Model', 'Experiment']}\n\nuqtils.ax_default(ax, 'Axial distance from anode (mm)', 'Axial ion velocity (km/s)',\n                  legend=leg)\n</code></pre> </li> <li> <p>Optionally adjust other plot settings:</p> <pre><code>with matplotlib.rc_context({'font.size': 14}):\n    plt.plot(...)\n</code></pre> </li> </ol>"},{"location":"start/","title":"Getting started","text":"<p>Assorted utilities for uncertainty quantification and scientific computing.</p>"},{"location":"start/#installation","title":"\u2699\ufe0f Installation","text":"<p><pre><code>pip install uqtils\n</code></pre> If you are using pdm in your own project, then you can use: <pre><code>pdm add uqtils\n\n# Or in editable mode from a local clone...\npdm add -e ./uqtils --dev\n</code></pre></p>"},{"location":"start/#quickstart","title":"\ud83d\udccd Quickstart","text":"<pre><code>import numpy as np\nimport uqtils as uq\n\nndim, nsamples = 3, 1000\n\nmu = np.random.rand(ndim)\ncov = np.eye(ndim)\n\nsamples = uq.normal_sample(mu, cov, nsamples)\nfig, ax = uq.ndscatter(samples)\n</code></pre>"},{"location":"start/#contributing","title":"\ud83c\udfd7\ufe0f Contributing","text":"<p>See the contribution guidelines.</p> <p><sup><sub>Made with the copier-numpy template.</sub></sup></p>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#normal-distribution","title":"Normal distribution","text":"<p>It is a frequent task to either sample from or evaluate the normal distribution. There are many ways to do this in existing libraries, like <code>np.random.randn()</code> or <code>scipy.stats.norm</code>. However, sometimes you deal with multivariate data of arbitrary shapes. What if you wanted to sample from <code>N</code> distinct multivariate Gaussians, each with their own covariances and means? Or perhaps you want to use the same covariance for all <code>N</code> distributions and then evaluate the pdf at <code>M</code> completely different locations?</p> <p>The code snippet here shows how we generalize normal sampling and pdfs using a vectorized implementation.</p> Vectorized sample/pdf<pre><code>import numpy as np\nimport uqtils as uq\n\nndim = 3\nshape = (5, ndim)\n\nmeans = np.random.randint(0, 10, size=shape).astype(np.float64)\ncov = np.eye(ndim) * 0.1\n\nsamples = uq.normal_sample(means, cov, size=1000)     # (1000, 5, 3)\npdfs = uq.normal_pdf(samples, means, cov)             # (1000, 5)\n\nfig, ax = uq.ndscatter(samples[:, 0, :])\n</code></pre>"},{"location":"tutorials/#gradients","title":"Gradients","text":"<p>It is another frequent task to obtain first and second derivatives of objective functions, say for maximum likelihood estimation. The generalizations of 1st and 2nd derivatives for multivariate, vector-valued functions (i.e. multiple inputs and multiple outputs) are the Jacobian and Hessian matrices. It is convenient to have functions that evaluate the Jacobian/Hessian for arbitrary numbers of inputs or outputs, including the limiting case of a single input and single output (which gives the normal 1st and 2nd derivatives that we all know and love).</p> <p>The code snippet here shows generalized finite-difference approximations of the Jacobian/Hessian for arbitrary input/output dimensions. The implementation is also vectorized over any number of extra axes, allowing you to evaluate multiple Jacobians/Hessians in one go.</p> Vectorized Jacobians/Hessians<pre><code>import numpy as np\nimport uqtils as uq\n\n# 1d example\ndef f(x):\n    return np.sin(x)\n\nx0 = 1.0\ndf_dx = uq.approx_jac(f, x0)\nd2f_dx2 = uq.approx_hess(f, x0)\n\n# Multivariate example\nn_in, n_out = 3, 2\ndef f(x):\n    x0, x1, x2 = [x[..., i] for i in range(n_in)]\n    f0 = x0 * x1 + x2\n    f1 = np.sin(x0)**2 + x2**3\n    return np.concatenate((f0[..., np.newaxis], f1[..., np.newaxis]), axis=-1)\n\nshape = (100, 5, n_in)\nx0 = np.random.rand(*shape)\njac  = uq.approx_jac(f, x0)      # (100, 5, n_out, n_in)\nhess = uq.approx_hess(f, x0)     # (100, 5, n_out, n_in, n_in)\n</code></pre>"},{"location":"tutorials/#markov-chain-monte-carlo","title":"Markov-Chain Monte Carlo","text":"<p>Here is an example of the delayed rejection adaptive Metropolis-Hastings (DRAM) algorithm for MCMC sampling. The implementation is vectorized over <code>nwalkers</code>, allowing multiple sampling chains to proceed in parallel.</p> MCMC sampling<pre><code>import numpy as np\nimport uqtils as uq\n\ndef fun(x):\n    mu = [1, 1]\n    cov = [[0.5, -0.1], [-0.1, 0.5]]\n    return uq.normal_pdf(x, mu, cov, logpdf=True)\n\nnsamples, nwalkers, ndim = 1000, 4, 2\nx0 = np.random.randn(nwalkers, ndim)\ncov0 = np.eye(ndim)\n\nsamples, log_pdf, accepted = uq.dram(fun, x0, nsamples, cov0=cov0)\n\nburn_in = int(0.1 * nsamples)\nsamples = samples[burn_in:, ...].reshape((-1, ndim))\nfig, ax = uq.ndscatter(samples, plot2d='hist')\n</code></pre>"},{"location":"tutorials/#sobol-sensitivity-analysis","title":"Sobol' sensitivity analysis","text":"<p>Here is an example of getting the Sobol' indices for the Ishigami test function.</p> Sobol' sensitivity analysis<pre><code>import numpy as np\nimport uqtils as uq\n\nmodel = lambda x: uq.ishigami(x)['y']\nsampler = lambda shape: np.random.rand(*shape, 3) * (2 * np.pi) - np.pi\nn_samples = 1000\n\nS1, ST = uq.sobol_sa(model, sampler, n_samples)\n</code></pre>"},{"location":"reference/","title":"<code>uqtils</code>","text":"<p>Assorted utilities for uncertainty quantification and scientific computing.</p> <ul> <li>Author - Joshua Eckels (eckelsjd.@umich.edu)</li> <li>License - GPL-3.0</li> </ul> <p>Includes:</p> <ul> <li>MCMC - A standard DRAM MCMC sampler.</li> <li>Gradients - Vectorized finite-difference implementation of Jacobian and Hessians.</li> <li>Plotting - Some plotting utilities for <code>matplotlib</code>.</li> <li>Sobol' - Sobol' global, variance-based sensitivity analysis.</li> </ul>"},{"location":"reference/#uqtils.approx_hess","title":"<code>approx_hess(func, theta, pert=0.01)</code>","text":"<p>Approximate Hessian of <code>func</code> at a specified <code>theta</code> location using finite difference approximation.</p> PARAMETER DESCRIPTION <code>func</code> <p>expects to be called as <code>func(theta) -&gt; (..., y_dim)</code></p> <p> </p> <code>theta</code> <p><code>(..., theta_dim)</code>, points to linearize model about</p> <p> TYPE: <code>Array</code> </p> <code>pert</code> <p>perturbation percent for approximate partial derivatives</p> <p> DEFAULT: <code>0.01</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(..., y_dim, theta_dim, theta_dim)</code>, the approximate Hessian <code>(theta_dim, theta_dim)</code> at all locations <code>(...,)</code> for vector-valued function of dimension <code>y_dim</code></p> Source code in <code>src/uqtils/gradient.py</code> <pre><code>def approx_hess(func, theta: Array, pert=0.01) -&gt; np.ndarray:\n    \"\"\"Approximate Hessian of `func` at a specified `theta` location using finite difference approximation.\n\n    :param func: expects to be called as `func(theta) -&gt; (..., y_dim)`\n    :param theta: `(..., theta_dim)`, points to linearize model about\n    :param pert: perturbation percent for approximate partial derivatives\n    :returns H: `(..., y_dim, theta_dim, theta_dim)`, the approximate Hessian `(theta_dim, theta_dim)` at all locations\n                `(...,)` for vector-valued function of dimension `y_dim`\n    \"\"\"\n    theta = np.atleast_1d(theta)\n    shape = theta.shape[:-1]                # (...,)\n    theta_dim = theta.shape[-1]             # Number of parameters\n    dtheta = pert * np.abs(theta)\n\n    # Make sure dtheta is not 0 anywhere\n    for i in range(theta_dim):\n        zero_idx = np.isclose(dtheta[..., i], 0)\n        if np.any(zero_idx):\n            subs_dtheta = pert * np.abs(np.mean(theta[..., i]))\n            if np.isclose(subs_dtheta, 0):\n                subs_dtheta = pert\n            dtheta[zero_idx, i] = subs_dtheta\n\n    # Return the Hessians (..., y_dim, theta_dim, theta_dim)\n    y_dim, H = None, None\n\n    for i in range(theta_dim):\n        for j in range(i, theta_dim):\n            # Allocate space at 4 grid points (n1=-1, p1=+1)\n            theta_n1_n1 = np.copy(theta)\n            theta_p1_p1 = np.copy(theta)\n            theta_n1_p1 = np.copy(theta)\n            theta_p1_n1 = np.copy(theta)\n\n            # Perturbations to theta in each direction\n            theta_n1_n1[..., i] -= dtheta[..., i]\n            theta_n1_n1[..., j] -= dtheta[..., j]\n            f_n1_n1 = func(theta_n1_n1)\n\n            theta_p1_p1[..., i] += dtheta[..., i]\n            theta_p1_p1[..., j] += dtheta[..., j]\n            f_p1_p1 = func(theta_p1_p1)\n\n            theta_n1_p1[..., i] -= dtheta[..., i]\n            theta_n1_p1[..., j] += dtheta[..., j]\n            f_n1_p1 = func(theta_n1_p1)\n\n            theta_p1_n1[..., i] += dtheta[..., i]\n            theta_p1_n1[..., j] -= dtheta[..., j]\n            f_p1_n1 = func(theta_p1_n1)\n\n            if H is None:\n                y_dim = f_p1_n1.shape[-1]\n                H = np.empty(shape + (y_dim, theta_dim, theta_dim))\n\n            res = (f_n1_n1 + f_p1_p1 - f_n1_p1 - f_p1_n1) / np.expand_dims(4 * dtheta[..., i] * dtheta[..., j],\n                                                                           axis=-1)\n            H[..., i, j] = res\n            H[..., j, i] = res\n\n    if y_dim == 1:\n        H = np.squeeze(H, axis=-3)\n        if theta_dim == 1:\n            H = np.squeeze(H, axis=(-1, -2))\n    return np.atleast_1d(H)\n</code></pre>"},{"location":"reference/#uqtils.approx_jac","title":"<code>approx_jac(func, theta, pert=0.01)</code>","text":"<p>Approximate Jacobian of <code>func</code> at a specified <code>theta</code> location using finite difference approximation.</p> PARAMETER DESCRIPTION <code>func</code> <p>expects to be called as <code>func(theta) -&gt; (..., y_dim)</code></p> <p> </p> <code>theta</code> <p><code>(..., theta_dim)</code>, points to linearize model about</p> <p> TYPE: <code>Array</code> </p> <code>pert</code> <p>perturbation percent for approximate partial derivatives</p> <p> DEFAULT: <code>0.01</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(..., y_dim, theta_dim)</code>, the approximate Jacobian <code>(y_dim, theta_dim)</code> at all locations <code>(...)</code></p> Source code in <code>src/uqtils/gradient.py</code> <pre><code>def approx_jac(func, theta: Array, pert=0.01) -&gt; np.ndarray:\n    \"\"\"Approximate Jacobian of `func` at a specified `theta` location using finite difference approximation.\n\n    :param func: expects to be called as `func(theta) -&gt; (..., y_dim)`\n    :param theta: `(..., theta_dim)`, points to linearize model about\n    :param pert: perturbation percent for approximate partial derivatives\n    :returns J: `(..., y_dim, theta_dim)`, the approximate Jacobian `(y_dim, theta_dim)` at all locations `(...)`\n    \"\"\"\n    theta = np.atleast_1d(theta)\n    shape = theta.shape[:-1]                # (...,)\n    theta_dim = theta.shape[-1]             # Number of parameters\n    dtheta = pert * np.abs(theta)\n\n    # Make sure dtheta is not 0 anywhere\n    for i in range(theta_dim):\n        zero_idx = np.isclose(dtheta[..., i], 0)\n        if np.any(zero_idx):\n            subs_dtheta = pert * np.abs(np.mean(theta[..., i]))\n            if np.isclose(subs_dtheta, 0):\n                subs_dtheta = pert\n            dtheta[zero_idx, i] = subs_dtheta\n\n    # Return the Jacobians (..., y_dim, theta_dim)\n    J, y_dim = None, None\n\n    for i in range(theta_dim):\n        theta_n1 = np.copy(theta)\n        theta_p1 = np.copy(theta)\n\n        # Perturbations to theta\n        theta_n1[..., i] -= dtheta[..., i]\n        theta_p1[..., i] += dtheta[..., i]\n        f_n1 = func(theta_n1)\n        f_p1 = func(theta_p1)\n\n        if J is None:\n            y_dim = f_p1.shape[-1]\n            J = np.empty(shape + (y_dim, theta_dim))\n\n        J[..., i] = (f_p1 - f_n1) / np.expand_dims(2 * dtheta[..., i], axis=-1)\n\n    if y_dim == 1:\n        J = np.squeeze(J, axis=-2)\n        if theta_dim == 1:\n            J = np.squeeze(J, axis=-1)\n    return np.atleast_1d(J)\n</code></pre>"},{"location":"reference/#uqtils.autocorrelation","title":"<code>autocorrelation(samples, maxlag=100, step=1)</code>","text":"<p>Compute the auto-correlation of a set of samples.</p> PARAMETER DESCRIPTION <code>samples</code> <p><code>(niter, nwalk, ndim)</code> samples returned from <code>dram</code> or a similar MCMC routine</p> <p> </p> <code>maxlag</code> <p>maximum distance to compute the correlation for</p> <p> DEFAULT: <code>100</code> </p> <code>step</code> <p>step between distances from 0 to <code>maxlag</code> for which to compute the correlations</p> <p> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <p>lags, autos, tau, ess - the lag times, auto-correlations, integrated auto-correlation, and effective sample sizes</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def autocorrelation(samples, maxlag=100, step=1):\n    \"\"\"Compute the auto-correlation of a set of samples.\n\n    :param samples: `(niter, nwalk, ndim)` samples returned from `dram` or a similar MCMC routine\n    :param maxlag: maximum distance to compute the correlation for\n    :param step: step between distances from 0 to `maxlag` for which to compute the correlations\n    :returns: lags, autos, tau, ess - the lag times, auto-correlations, integrated auto-correlation,\n              and effective sample sizes\n    \"\"\"\n    niter, nwalk, ndim = samples.shape\n    mean = np.mean(samples, axis=0)\n    var = np.sum((samples - mean[np.newaxis, ...]) ** 2, axis=0)\n\n    lags = np.arange(0, maxlag, step)\n    autos = np.zeros((len(lags), nwalk, ndim))\n    for zz, lag in enumerate(lags):\n        # compute the covariance between all samples *lag apart*\n        for ii in range(niter - lag):\n            autos[zz, ...] += (samples[ii, ...] - mean) * (samples[ii + lag, ...] - mean)\n        autos[zz, ...] /= var\n    tau = 1 + 2 * np.sum(autos, axis=0)     # Integrated auto-correlation\n    ess = niter / tau                       # Effective sample size\n    return lags, autos, tau, ess\n</code></pre>"},{"location":"reference/#uqtils.ax_default","title":"<code>ax_default(ax, xlabel='', ylabel='', legend=None, cmap='tab10')</code>","text":"<p>Nice default plt formatting for plotting X-Y data.</p> PARAMETER DESCRIPTION <code>ax</code> <p>the axes to apply these settings to</p> <p> TYPE: <code>Axes</code> </p> <code>xlabel</code> <p>the xlabel to set for <code>ax</code></p> <p> DEFAULT: <code>''</code> </p> <code>ylabel</code> <p>the ylabel to set for <code>ax</code></p> <p> DEFAULT: <code>''</code> </p> <code>legend</code> <p>will display a legend if bool(legend) is truthy, can pass a dict of legend kwargs here (optional)</p> <p> DEFAULT: <code>None</code> </p> <code>cmap</code> <p>colormap to use for cycling</p> <p> DEFAULT: <code>'tab10'</code> </p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def ax_default(ax: plt.Axes, xlabel='', ylabel='', legend=None, cmap='tab10'):\n    \"\"\"Nice default plt formatting for plotting X-Y data.\n\n    :param ax: the axes to apply these settings to\n    :param xlabel: the xlabel to set for `ax`\n    :param ylabel: the ylabel to set for `ax`\n    :param legend: will display a legend if bool(legend) is truthy, can pass a dict of legend kwargs here (optional)\n    :param cmap: colormap to use for cycling\n    \"\"\"\n    default_leg = {'fancybox': True, 'facecolor': 'white', 'framealpha': 1, 'loc': 'best', 'edgecolor': 'k'}\n    leg_use = legend if isinstance(legend, dict) else default_leg\n    for key, val in default_leg.items():\n        if key not in leg_use:\n            leg_use[key] = val\n\n    ax.set_prop_cycle(_get_cycle(cmap))\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.tick_params(axis='both', which='both', direction='in')\n    if legend:\n        leg = ax.legend(**leg_use)\n        return leg\n</code></pre>"},{"location":"reference/#uqtils.dram","title":"<code>dram(logpdf, x0, niter, cov0=None, gamma=0.5, eps=1e-06, adapt_after=100, adapt_interval=10, delayed=True, progress=True, filename=None)</code>","text":"<p>Delayed adaptive metropolis-hastings MCMC with a Gaussian proposal.</p> PARAMETER DESCRIPTION <code>logpdf</code> <p>log PDF function of target distribution</p> <p> </p> <code>x0</code> <p><code>(nwalkers, ndim)</code> initial parameter samples, ignored if samples exist in <code>filename</code></p> <p> </p> <code>cov0</code> <p><code>(ndim, ndim)</code> the initial proposal covariance, defaults to identity or <code>cov</code> value in filename</p> <p> DEFAULT: <code>None</code> </p> <code>niter</code> <p>number of iterations</p> <p> </p> <code>gamma</code> <p>scale factor for the covariance matrix for delayed rejection step</p> <p> DEFAULT: <code>0.5</code> </p> <code>eps</code> <p>small constant for making sure covariance is well-conditioned</p> <p> DEFAULT: <code>1e-06</code> </p> <code>adapt_after</code> <p>the number of iterations before covariance adaptation begins (ignored if &lt;=0)</p> <p> DEFAULT: <code>100</code> </p> <code>adapt_interval</code> <p>the number of iterations between each covariance adaptation (ignored if <code>adapt_after&lt;=0</code>)</p> <p> DEFAULT: <code>10</code> </p> <code>delayed</code> <p>whether to try to sample again after first rejection</p> <p> DEFAULT: <code>True</code> </p> <code>progress</code> <p>whether to display progress of the sampler</p> <p> DEFAULT: <code>True</code> </p> <code>filename</code> <p>if specified, an hdf5 file to save results to. If the file already has dram results, the new samples will be appended. Follows the same format as the <code>emcee</code> library</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p><code>samples, log_pdf, acceptance</code> - <code>(niter, nwalkers, ndim)</code> samples of the target distribution, the logpdf values at these locations, and the cumulative number of accepted samples per walker</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def dram(logpdf, x0, niter, cov0=None, gamma=0.5, eps=1e-6, adapt_after=100, adapt_interval=10,\n         delayed=True, progress=True, filename=None):\n    \"\"\"Delayed adaptive metropolis-hastings MCMC with a Gaussian proposal.\n\n    :param logpdf: log PDF function of target distribution\n    :param x0: `(nwalkers, ndim)` initial parameter samples, ignored if samples exist in `filename`\n    :param cov0: `(ndim, ndim)` the initial proposal covariance, defaults to identity or `cov` value in filename\n    :param niter: number of iterations\n    :param gamma: scale factor for the covariance matrix for delayed rejection step\n    :param eps: small constant for making sure covariance is well-conditioned\n    :param adapt_after: the number of iterations before covariance adaptation begins (ignored if &lt;=0)\n    :param adapt_interval: the number of iterations between each covariance adaptation (ignored if `adapt_after&lt;=0`)\n    :param delayed: whether to try to sample again after first rejection\n    :param progress: whether to display progress of the sampler\n    :param filename: if specified, an hdf5 file to save results to. If the file already has dram results, the new\n                     samples will be appended. Follows the same format as the `emcee` library\n    :returns: `samples, log_pdf, acceptance` - `(niter, nwalkers, ndim)` samples of the target distribution, the logpdf\n              values at these locations, and the cumulative number of accepted samples per walker\n    \"\"\"\n    # Override x0, cov0 if filename already has samples\n    try:\n        if filename is not None:\n            with h5py.File(filename, 'a') as fd:\n                group = fd.get('mcmc', None)\n                if group is not None:\n                    x0 = group['chain'][-1, ...]\n                    if cov0 is None:\n                        cov0 = np.array(group['cov'])  # only override if cov0 is not passed in\n                    niter += 1\n    except Exception as e:\n        warnings.warn(str(e))\n\n    # Initialize\n    x0 = np.atleast_2d(x0)\n    nwalk, ndim = x0.shape\n    cov0 = np.eye(ndim) if cov0 is None else cov0\n    sd = (2.4**2/ndim)\n    curr_cov = np.broadcast_to(cov0, (nwalk, ndim, ndim)).copy().astype(x0.dtype)\n    curr_chol = np.linalg.cholesky(curr_cov)\n    adapt_cov = curr_cov.copy()  # adaptive covariance\n    curr_mean = x0\n    curr_loc_logpdf = logpdf(x0)\n    samples = np.empty((niter, nwalk, ndim), dtype=x0.dtype)\n    log_pdf = np.empty((niter, nwalk), dtype=x0.dtype)\n    accepted = np.zeros((nwalk,), dtype=x0.dtype)\n    samples[0, ...] = x0\n    log_pdf[0, ...] = curr_loc_logpdf\n\n    def accept_first(curr_log, prop_log):\n        with np.errstate(over='ignore'):\n            # Overflow values go to -&gt; infty, so they will always get accepted\n            ret = np.minimum(1.0, np.exp(prop_log - curr_log))\n        return ret\n\n    # Main sample loop\n    iterable = tqdm.tqdm(range(niter-1)) if progress else range(niter-1)\n    # --8&lt;-- [start:dram]\n    for i in iterable:\n        # Propose sample\n        x1 = samples[i, ...]\n        y1 = normal_sample(x1, curr_chol, sqrt=True)    # (nwalkers, ndim)\n        x1_log = curr_loc_logpdf\n        y1_log = logpdf(y1)\n\n        # Compute first acceptance\n        with np.errstate(invalid='ignore'):\n            a1 = y1_log - x1_log                        # (nwalkers,)\n        a1_idx = a1 &gt; 0\n        a1_idx |= np.log(np.random.rand(nwalk)) &lt; a1\n        samples[i + 1, a1_idx, :] = y1[a1_idx, :]\n        samples[i + 1, ~a1_idx, :] = x1[~a1_idx, :]\n        curr_loc_logpdf[a1_idx] = y1_log[a1_idx]\n        accepted[a1_idx] += 1\n\n        # Second level proposal\n        if delayed and np.any(~a1_idx):\n            y2 = normal_sample(x1[~a1_idx, :], curr_chol[~a1_idx, ...] * np.sqrt(gamma), sqrt=True)\n            y2_log = logpdf(y2)\n            with ((np.errstate(divide='ignore', invalid='ignore'))):\n                # If a(y2, y1)=1, then log(1-a(y2,y1)) -&gt; -infty and a2 -&gt; 0\n                frac_1 = y2_log - x1_log[~a1_idx]\n                frac_2 = (normal_pdf(y1[~a1_idx, :], y2, curr_cov[~a1_idx, ...], logpdf=True) -\n                          normal_pdf(y1[~a1_idx, :], x1[~a1_idx, :], curr_cov[~a1_idx, ...], logpdf=True))\n                frac_3 = (np.log(1 - accept_first(y2_log, y1_log[~a1_idx])) -\n                          np.log(1 - np.minimum(1.0, np.exp(a1[~a1_idx]))))\n                a2 = frac_1 + frac_2 + frac_3\n            a2_idx = a2 &gt; 0\n            a2_idx |= np.log(np.random.rand(a2.shape[0])) &lt; a2\n\n            sample_a2_idx = np.where(~a1_idx)[0][a2_idx]  # Indices that were False the 1st time, then true the 2nd\n            samples[i + 1, sample_a2_idx, :] = y2[a2_idx, :]\n            curr_loc_logpdf[sample_a2_idx] = y2_log[a2_idx]\n            accepted[sample_a2_idx] += 1\n\n        log_pdf[i+1, ...] = curr_loc_logpdf\n\n        # Update the sample mean and cov every iteration\n        if adapt_after &gt; 0:\n            k = i + 1\n            last_mean = curr_mean.copy()\n            curr_mean = (1/(k+1)) * samples[k, ...] + (k/(k+1))*last_mean\n            mult = (np.eye(ndim) * eps + k * last_mean[..., np.newaxis] @ last_mean[..., np.newaxis, :] -\n                    (k + 1) * curr_mean[..., np.newaxis] @ curr_mean[..., np.newaxis, :] +\n                    samples[k, ..., np.newaxis] @ samples[k, ..., np.newaxis, :])\n            adapt_cov = ((k - 1) / k) * adapt_cov + (sd / k) * mult\n\n            if k &gt; adapt_after and k % adapt_interval == 0:\n                try:\n                    curr_chol[:] = np.linalg.cholesky(adapt_cov)\n                    curr_cov[:] = adapt_cov[:]\n                except np.linalg.LinAlgError:\n                    warnings.warn(f\"Non-PSD matrix at k={k}. Ignoring...\")\n    # --8&lt;-- [end:dram]\n\n    try:\n        if filename is not None:\n            with h5py.File(filename, 'a') as fd:\n                group = fd.get('mcmc', None)\n                if group is not None:\n                    samples = np.concatenate((group['chain'], samples[1:, ...]), axis=0)\n                    log_pdf = np.concatenate((group['log_pdf'], log_pdf[1:, ...]), axis=0)\n                    accepted += group['accepted']\n                    del group['chain']\n                    del group['log_pdf']\n                    del group['accepted']\n                    del group['cov']\n                fd.create_dataset('mcmc/chain', data=samples)\n                fd.create_dataset('mcmc/log_pdf', data=log_pdf)\n                fd.create_dataset('mcmc/accepted', data=accepted)\n                fd.create_dataset('mcmc/cov', data=curr_cov)\n    except Exception as e:\n        warnings.warn(str(e))\n\n    return samples, log_pdf, accepted\n</code></pre>"},{"location":"reference/#uqtils.format_input","title":"<code>format_input(x, ndim)</code>","text":"<p>Helper function to make sure input <code>x</code> is an <code>ndarray</code> of shape <code>(..., ndim)</code>.</p> PARAMETER DESCRIPTION <code>x</code> <p>if 1d-like as <code>(n,)</code>, then converted to 2d as <code>(1, n) if n==ndim or (n, 1) if ndim==1</code></p> <p> TYPE: <code>Array</code> </p> <code>ndim</code> <p>the dimension of the inputs</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tuple[bool, ndarray]</code> <p><code>x</code> as at least a 2d array <code>(..., ndim)</code>, and whether <code>x</code> was originally 1d-like</p> Source code in <code>src/uqtils/uq_types.py</code> <pre><code>def format_input(x: Array, ndim: int) -&gt; tuple[bool, np.ndarray]:\n    \"\"\"Helper function to make sure input `x` is an `ndarray` of shape `(..., ndim)`.\n\n    :param x: if 1d-like as `(n,)`, then converted to 2d as `(1, n) if n==ndim or (n, 1) if ndim==1`\n    :param ndim: the dimension of the inputs\n    :returns: `x` as at least a 2d array `(..., ndim)`, and whether `x` was originally 1d-like\n    \"\"\"\n    x = np.atleast_1d(x)\n    is_1d = len(x.shape) == 1\n    if is_1d:\n        if x.shape[0] != ndim and ndim &gt; 1:\n            raise ValueError(f'Input x shape {x.shape} is incompatible with ndim of {ndim}')\n        x = np.expand_dims(x, axis=0 if x.shape[0] == ndim else 1)\n\n    return is_1d, x\n</code></pre>"},{"location":"reference/#uqtils.is_positive_definite","title":"<code>is_positive_definite(A)</code>","text":"<p>Returns true when input is positive-definite, via Cholesky.</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def is_positive_definite(A):\n    \"\"\"Returns true when input is positive-definite, via Cholesky.\"\"\"\n    try:\n        _ = np.linalg.cholesky(A)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n</code></pre>"},{"location":"reference/#uqtils.ishigami","title":"<code>ishigami(x, a=7.0, b=0.1)</code>","text":"<p>For testing Sobol indices: Ishigami function</p> Source code in <code>src/uqtils/sobol.py</code> <pre><code>def ishigami(x, a=7.0, b=0.1):\n    \"\"\"For testing Sobol indices: [Ishigami function](https://doi.org/10.1109/ISUMA.1990.151285)\"\"\"\n    return {'y': np.sin(x[..., 0:1]) + a*np.sin(x[..., 1:2])**2 + b*(x[..., 2:3]**4)*np.sin(x[..., 0:1])}\n</code></pre>"},{"location":"reference/#uqtils.ndscatter","title":"<code>ndscatter(samples, labels=None, tick_fmts=None, plot1d=None, plot2d='scatter', cmap='viridis', bins=20, cmin=0, z=None, cb_label=None, cb_norm='linear', subplot_size=3, cov_overlay=None)</code>","text":"<p>Triangle scatter plots of n-dimensional samples.</p> <p>Warning</p> <p>Best for <code>dim &lt; 10</code>. You can shrink the <code>subplot_size</code> to assist graphics loading time.</p> PARAMETER DESCRIPTION <code>samples</code> <p><code>(N, dim)</code> samples to plot</p> <p> TYPE: <code>ndarray</code> </p> <code>labels</code> <p>list of axis labels of length <code>dim</code></p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>tick_fmts</code> <p>list of str.format() specifiers for ticks, e.g <code>['{x: ^10.2f}', ...]</code>, of length <code>dim</code></p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>plot1d</code> <p>'hist' or 'kde' for 1d marginals, defaults to plot2d if None</p> <p> TYPE: <code>Literal['kde', 'hist']</code> DEFAULT: <code>None</code> </p> <code>plot2d</code> <p>'hist' for 2d hist plot, 'kde' for kernel density estimation, 'hex', or 'scatter' (default)</p> <p> TYPE: <code>Literal['scatter', 'kde', 'hist', 'hex']</code> DEFAULT: <code>'scatter'</code> </p> <code>cmap</code> <p>the matplotlib string specifier of a colormap</p> <p> DEFAULT: <code>'viridis'</code> </p> <code>bins</code> <p>number of bins in each dimension for histogram marginals</p> <p> DEFAULT: <code>20</code> </p> <code>cmin</code> <p>the minimum bin count below which the bins are not displayed</p> <p> DEFAULT: <code>0</code> </p> <code>z</code> <p><code>(N,)</code> a performance metric corresponding to <code>samples</code>, used to color code the scatter plot if provided</p> <p> TYPE: <code>ndarray</code> DEFAULT: <code>None</code> </p> <code>cb_label</code> <p>label for color bar (if <code>z</code> is provided)</p> <p> DEFAULT: <code>None</code> </p> <code>cb_norm</code> <p><code>str</code> or <code>plt.colors.Normalize</code>, normalization method for plotting <code>z</code> on scatter plot</p> <p> DEFAULT: <code>'linear'</code> </p> <code>subplot_size</code> <p>size in inches of a single 2d marginal subplot</p> <p> DEFAULT: <code>3</code> </p> <code>cov_overlay</code> <p><code>(ndim, ndim)</code> a covariance matrix to overlay as a Gaussian kde over the samples</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>the <code>plt</code> Figure and Axes objects, (returns an additional <code>cb_fig, cb_ax</code> if <code>z</code> is specified)</p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def ndscatter(samples: np.ndarray, labels: list[str] = None, tick_fmts: list[str] = None,\n              plot1d: Literal['kde', 'hist'] = None, plot2d: Literal['scatter', 'kde', 'hist', 'hex'] = 'scatter',\n              cmap='viridis', bins=20, cmin=0, z: np.ndarray = None, cb_label=None, cb_norm='linear',\n              subplot_size=3, cov_overlay=None):\n    \"\"\"Triangle scatter plots of n-dimensional samples.\n\n    !!! Warning\n        Best for `dim &lt; 10`. You can shrink the `subplot_size` to assist graphics loading time.\n\n    :param samples: `(N, dim)` samples to plot\n    :param labels: list of axis labels of length `dim`\n    :param tick_fmts: list of str.format() specifiers for ticks, e.g `['{x: ^10.2f}', ...]`, of length `dim`\n    :param plot1d: 'hist' or 'kde' for 1d marginals, defaults to plot2d if None\n    :param plot2d: 'hist' for 2d hist plot, 'kde' for kernel density estimation, 'hex', or 'scatter' (default)\n    :param cmap: the matplotlib string specifier of a colormap\n    :param bins: number of bins in each dimension for histogram marginals\n    :param cmin: the minimum bin count below which the bins are not displayed\n    :param z: `(N,)` a performance metric corresponding to `samples`, used to color code the scatter plot if provided\n    :param cb_label: label for color bar (if `z` is provided)\n    :param cb_norm: `str` or `plt.colors.Normalize`, normalization method for plotting `z` on scatter plot\n    :param subplot_size: size in inches of a single 2d marginal subplot\n    :param cov_overlay: `(ndim, ndim)` a covariance matrix to overlay as a Gaussian kde over the samples\n    :returns fig, axs: the `plt` Figure and Axes objects, (returns an additional `cb_fig, cb_ax` if `z` is specified)\n    \"\"\"\n    N, dim = samples.shape\n    x_min = np.min(samples, axis=0)\n    x_max = np.max(samples, axis=0)\n    show_colorbar = z is not None\n    if labels is None:\n        labels = [f\"x{i}\" for i in range(dim)]\n    if z is None:\n        z = plt.get_cmap(cmap)([0])\n    if cb_label is None:\n        cb_label = 'Performance metric'\n\n    def tick_format_func(value, pos):\n        if np.isclose(value, 0):\n            return f'{value:.2f}'\n        if abs(value) &gt; 1000:\n            return f'{value:.2E}'\n        if abs(value) &gt; 100:\n            return f'{int(value):d}'\n        if abs(value) &gt; 1:\n            return f'{value:.2f}'\n        if abs(value) &gt; 0.01:\n            return f'{value:.4f}'\n        if abs(value) &lt; 0.01:\n            return f'{value:.2E}'\n    default_ticks = FuncFormatter(tick_format_func)\n    # if tick_fmts is None:\n    #     tick_fmts = ['{x:.2G}' for i in range(dim)]\n\n    # Set up triangle plot formatting\n    fig, axs = plt.subplots(dim, dim, sharex='col', sharey='row')\n    for i in range(dim):\n        for j in range(dim):\n            ax = axs[i, j]\n            if i == j:                      # 1d marginals on diagonal\n                # ax.get_shared_y_axes().remove(ax)\n                ax._shared_axes['y'].remove(ax)\n                ax.spines['top'].set_visible(False)\n                ax.spines['right'].set_visible(False)\n                ax.spines['left'].set_visible(False)\n                if i == 0:\n                    ax.get_yaxis().set_ticks([])\n            if j &gt; i:                       # Clear the upper triangle\n                ax.axis('off')\n            if i == dim - 1:                # Bottom row\n                ax.set_xlabel(labels[j])\n                ax.xaxis.set_major_locator(AutoLocator())\n                formatter = StrMethodFormatter(tick_fmts[j]) if tick_fmts is not None else default_ticks\n                ax.xaxis.set_major_formatter(formatter)\n            if j == 0 and i &gt; 0:            # Left column\n                ax.set_ylabel(labels[i])\n                ax.yaxis.set_major_locator(AutoLocator())\n                formatter = StrMethodFormatter(tick_fmts[i]) if tick_fmts is not None else default_ticks\n                ax.yaxis.set_major_formatter(formatter)\n\n    if cov_overlay is not None:\n        x_overlay = normal_sample(np.mean(samples, axis=0), cov_overlay, 5000)\n\n    # Plot marginals\n    for i in range(dim):\n        for j in range(dim):\n            ax = axs[i, j]\n            if i == j:                      # 1d marginals (on diagonal)\n                c = plt.get_cmap(cmap)(0)\n                plot = plot1d if plot1d is not None else plot2d\n                if plot == 'kde':\n                    kernel = st.gaussian_kde(samples[:, i])\n                    x = np.linspace(x_min[i], x_max[i], 500)\n                    ax.fill_between(x, y1=kernel(x), y2=0, lw=0, alpha=0.3, facecolor=c)\n                    ax.plot(x, kernel(x), ls='-', c=c, lw=1.5)\n                else:\n                    ax.hist(samples[:, i], edgecolor='black', color=c, density=True, alpha=0.5,\n                            linewidth=1.2, bins=bins)\n                if cov_overlay is not None:\n                    kernel = st.gaussian_kde(x_overlay[:, i])\n                    x = np.linspace(x_min[i], x_max[i], 500)\n                    ax.fill_between(x, y1=kernel(x), y2=0, lw=0, alpha=0.5, facecolor=[0.5, 0.5, 0.5])\n                    ax.plot(x, kernel(x), ls='-', c='k', lw=1.5, alpha=0.5)\n                bottom, top = ax.get_ylim()\n                ax.set_ylim([0, top])\n            if j &lt; i:                       # 2d marginals (lower triangle)\n                ax.set_xlim([x_min[j], x_max[j]])\n                ax.set_ylim([x_min[i], x_max[i]])\n                if plot2d == 'scatter':\n                    sc = ax.scatter(samples[:, j], samples[:, i], s=1.5, c=z, cmap=cmap, norm=cb_norm)\n                elif plot2d == 'hist':\n                    ax.hist2d(samples[:, j], samples[:, i], bins=bins, cmap=cmap, cmin=cmin)\n                elif plot2d == 'kde':\n                    kernel = st.gaussian_kde(samples[:, [j, i]].T)\n                    xg, yg = np.meshgrid(np.linspace(x_min[j], x_max[j], 40), np.linspace(x_min[i], x_max[i], 40))\n                    x = np.vstack([xg.ravel(), yg.ravel()])\n                    zg = np.reshape(kernel(x), xg.shape)\n                    cs = ax.contourf(xg, yg, zg, 5, cmap=cmap, alpha=0.9, extend='both')\n                    cs.cmap.set_under('white')\n                    cs.changed()\n                    ax.contour(xg, yg, zg, 5, colors=[(0.5, 0.5, 0.5)], linewidths=1.2)\n                elif plot2d == 'hex':\n                    ax.hexbin(samples[:, j], samples[:, i], gridsize=bins, cmap=cmap, mincnt=cmin)\n                else:\n                    raise NotImplementedError('This plot type is not known. plot2d=[\"hist\", \"kde\", \"scatter\"]')\n\n                if cov_overlay is not None:\n                    kernel = st.gaussian_kde(x_overlay[:, [j, i]].T)\n                    xg, yg = np.meshgrid(np.linspace(x_min[j], x_max[j], 40), np.linspace(x_min[i], x_max[i], 40))\n                    x = np.vstack([xg.ravel(), yg.ravel()])\n                    zg = np.reshape(kernel(x), xg.shape)\n                    ax.contourf(xg, yg, zg, 4, cmap='Greys', alpha=0.4)\n                    ax.contour(xg, yg, zg, 4, colors='k', linewidths=1.5, alpha=0.6)\n\n    fig.set_size_inches(subplot_size * dim, subplot_size * dim)\n    fig.tight_layout()\n\n    # Plot colorbar in standalone figure\n    if show_colorbar and plot2d == 'scatter':\n        cb_fig, cb_ax = plt.subplots(figsize=(1.5, 6))\n        cb_fig.subplots_adjust(right=0.7)\n        cb_fig.colorbar(sc, cax=cb_ax, orientation='vertical', label=cb_label)\n        cb_fig.tight_layout()\n        return fig, axs, cb_fig, cb_ax\n\n    return fig, axs\n</code></pre>"},{"location":"reference/#uqtils.nearest_positive_definite","title":"<code>nearest_positive_definite(A)</code>","text":"<p>Find the nearest positive-definite matrix to input.</p> <p>A Python port of John D'Errico's <code>nearestSPD</code> MATLAB code [1], which credits [2]. [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\", 1988</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def nearest_positive_definite(A):\n    \"\"\"Find the nearest positive-definite matrix to input.\n\n    A Python port of John D'Errico's `nearestSPD` MATLAB code [1], which credits [2].\n    [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd\n    [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\", 1988\n    \"\"\"\n    B = (A + A.T) / 2\n    _, s, V = np.linalg.svd(B)\n    H = np.dot(V.T, np.dot(np.diag(s), V))\n    A2 = (B + H) / 2\n    A3 = (A2 + A2.T) / 2\n    if is_positive_definite(A3):\n        return A3\n    spacing = np.spacing(np.linalg.norm(A))\n    # The above is different from [1]. It appears that MATLAB's `chol` Cholesky\n    # decomposition will accept matrixes with exactly 0-eigenvalue, whereas\n    # Numpy's will not. So where [1] uses `eps(mineig)` (where `eps` is Matlab\n    # for `np.spacing`), we use the above definition. CAVEAT: our `spacing`\n    # will be much larger than [1]'s `eps(mineig)`, since `mineig` is usually on\n    # the order of 1e-16, and `eps(1e-16)` is on the order of 1e-34, whereas\n    # `spacing` will, for Gaussian random matrixes of small dimension, be on\n    # othe order of 1e-16. In practice, both ways converge, as the unit test\n    # below suggests.\n    eye = np.eye(A.shape[0])\n    k = 1\n    while not is_positive_definite(A3):\n        mineig = np.min(np.real(np.linalg.eigvals(A3)))\n        A3 += eye * (-mineig * k ** 2 + spacing)\n        k += 1\n\n    return A3\n</code></pre>"},{"location":"reference/#uqtils.normal_pdf","title":"<code>normal_pdf(x, mean, cov, logpdf=False)</code>","text":"<p>Compute the Gaussian pdf at each <code>x</code> location (pretty much however you want).</p> PARAMETER DESCRIPTION <code>x</code> <p><code>(..., dim)</code>, the locations to evaluate the pdf at</p> <p> TYPE: <code>Array</code> </p> <code>mean</code> <p><code>(..., dim)</code>, expected values, where dim is the random variable dimension</p> <p> TYPE: <code>Array</code> </p> <code>cov</code> <p><code>(..., dim, dim)</code>, covariance matrices</p> <p> TYPE: <code>Array</code> </p> <code>logpdf</code> <p>whether to return the logpdf instead</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(...,)</code> the pdf values at <code>x</code></p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def normal_pdf(x: Array, mean: Array, cov: Array, logpdf: bool = False) -&gt; np.ndarray:\n    \"\"\"Compute the Gaussian pdf at each `x` location (pretty much however you want).\n\n    :param x: `(..., dim)`, the locations to evaluate the pdf at\n    :param mean: `(..., dim)`, expected values, where dim is the random variable dimension\n    :param cov: `(..., dim, dim)`, covariance matrices\n    :param logpdf: whether to return the logpdf instead\n    :returns: `(...,)` the pdf values at `x`\n    \"\"\"\n    x = np.atleast_1d(x)\n    mean = np.atleast_1d(mean)\n    cov = np.atleast_2d(cov)\n    dim = cov.shape[-1]\n\n    preexp = 1 / ((2*np.pi)**(dim/2) * np.linalg.det(cov)**(1/2))\n    diff = x - mean\n    diff_col = np.expand_dims(diff, axis=-1)    # (..., dim, 1)\n    diff_row = np.expand_dims(diff, axis=-2)    # (..., 1, dim)\n    inexp = np.squeeze(diff_row @ np.linalg.inv(cov) @ diff_col, axis=(-1, -2))\n\n    pdf = np.log(preexp) - 0.5 * inexp if logpdf else preexp * np.exp(-0.5 * inexp)\n\n    return pdf\n</code></pre>"},{"location":"reference/#uqtils.normal_sample","title":"<code>normal_sample(mean, cov, size=(), sqrt=False)</code>","text":"<p>Generic batch sample multivariate normal distributions (pretty much however you want).</p> <p>Note</p> <p>The provided <code>mean</code> and <code>cov</code> should match along the last dimension, that is the dimension of the random variables to sample. If you want to sample a 1d Gaussian, then you can specify both the mean and covariance as scalars. However, as long as the mean and covariance are broadcastable in size, then you can use this function however you want, (i.e. sample many multivariate distributions at once, all with different means and covariances, etc., just get creative)</p> PARAMETER DESCRIPTION <code>mean</code> <p><code>(..., dim)</code>, expected values, where <code>dim</code> is the random variable dimension</p> <p> TYPE: <code>Array</code> </p> <code>cov</code> <p><code>(..., dim, dim)</code>, covariance matrices (or the sqrt(cov) if <code>sqrt=True</code>)</p> <p> TYPE: <code>Array</code> </p> <code>size</code> <p>shape of additional samples</p> <p> TYPE: <code>tuple | int</code> DEFAULT: <code>()</code> </p> <code>sqrt</code> <p>whether <code>cov</code> was passed in already as the <code>sqrt(cov)</code> via cholesky decomposition</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(*size, ..., dim)</code>, samples from multivariate distributions</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def normal_sample(mean: Array, cov: Array, size: tuple | int = (), sqrt=False) -&gt; np.ndarray:\n    \"\"\"Generic batch sample multivariate normal distributions (pretty much however you want).\n\n    !!! Note\n        The provided `mean` and `cov` should match along the last dimension, that is the dimension of the random\n        variables to sample. If you want to sample a 1d Gaussian, then you can specify both the mean and covariance\n        as scalars. However, as long as the mean and covariance are broadcastable in size, then you can use this\n        function however you want, (i.e. sample many multivariate distributions at once, all with different means\n        and covariances, etc., just get creative)\n\n    :param mean: `(..., dim)`, expected values, where `dim` is the random variable dimension\n    :param cov: `(..., dim, dim)`, covariance matrices (or the sqrt(cov) if `sqrt=True`)\n    :param size: shape of additional samples\n    :param sqrt: whether `cov` was passed in already as the `sqrt(cov)` via cholesky decomposition\n    :returns samples: `(*size, ..., dim)`, samples from multivariate distributions\n    \"\"\"\n    mean = np.atleast_1d(mean)\n    cov = np.atleast_2d(cov)\n    sqrt_cov = cov if sqrt else np.linalg.cholesky(cov)\n\n    if isinstance(size, int):\n        size = (size, )\n    shape = size + np.broadcast_shapes(mean.shape, cov.shape[:-1])\n    x_normal = np.random.standard_normal((*shape, 1)).astype(mean.dtype)\n    samples = np.squeeze(sqrt_cov @ x_normal, axis=-1) + mean\n    return samples\n</code></pre>"},{"location":"reference/#uqtils.plot_slice","title":"<code>plot_slice(funs, bds, x0=None, x_idx=None, y_idx=None, N=50, random_walk=False, xlabels=None, ylabels=None, cmap='viridis', fun_labels=None)</code>","text":"<p>Helper function to plot 1d slices of a function(s) over inputs.</p> PARAMETER DESCRIPTION <code>funs</code> <p>function callable as <code>y=f(x)</code>, with <code>x</code> as <code>(..., xdim)</code> and <code>y</code> as <code>(..., ydim)</code>, can also be a list of functions to evaluate and plot together.</p> <p> </p> <code>bds</code> <p>list of tuples of <code>(min, max)</code> specifying the bounds of the inputs</p> <p> TYPE: <code>list[tuple]</code> </p> <code>x0</code> <p>the default values for all inputs; defaults to middle of <code>bds</code></p> <p> TYPE: <code>Array</code> DEFAULT: <code>None</code> </p> <code>x_idx</code> <p>list of input indices to take 1d slices of</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>y_idx</code> <p>list of output indices to plot 1d slices of</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>N</code> <p>the number of points to take in each 1d slice</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> <code>random_walk</code> <p>whether to slice in a random d-dimensional direction or hold all params const while slicing</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>xlabels</code> <p>list of labels for the inputs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>ylabels</code> <p>list of labels for the outputs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>cmap</code> <p>the name of the matplotlib colormap to use</p> <p> DEFAULT: <code>'viridis'</code> </p> <code>fun_labels</code> <p>the legend labels if plotting multiple functions on each plot</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p><code>fig, ax</code> with <code>num_inputs</code> by <code>num_outputs</code> subplots</p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def plot_slice(funs, bds: list[tuple], x0: Array = None, x_idx: list[int] = None,\n               y_idx: list[int] = None, N: int = 50, random_walk: bool = False, xlabels: list[str] = None,\n               ylabels: list[str] = None, cmap='viridis', fun_labels=None):\n    \"\"\"Helper function to plot 1d slices of a function(s) over inputs.\n\n    :param funs: function callable as `y=f(x)`, with `x` as `(..., xdim)` and `y` as `(..., ydim)`, can also be a list\n                of functions to evaluate and plot together.\n    :param bds: list of tuples of `(min, max)` specifying the bounds of the inputs\n    :param x0: the default values for all inputs; defaults to middle of `bds`\n    :param x_idx: list of input indices to take 1d slices of\n    :param y_idx: list of output indices to plot 1d slices of\n    :param N: the number of points to take in each 1d slice\n    :param random_walk: whether to slice in a random d-dimensional direction or hold all params const while slicing\n    :param xlabels: list of labels for the inputs\n    :param ylabels: list of labels for the outputs\n    :param cmap: the name of the matplotlib colormap to use\n    :param fun_labels: the legend labels if plotting multiple functions on each plot\n    :returns: `fig, ax` with `num_inputs` by `num_outputs` subplots\n    \"\"\"\n    funs = funs if isinstance(funs, list) else [funs]\n    x_idx = list(np.arange(0, min(3, len(bds)))) if x_idx is None else x_idx\n    y_idx = [0] if y_idx is None else y_idx\n    xlabels = [f'x{i}' for i in range(len(x_idx))] if xlabels is None else xlabels\n    ylabels = [f'QoI {i}' for i in range(len(y_idx))] if ylabels is None else ylabels\n    fun_labels = [f'fun {i}' for i in range(len(funs))] if fun_labels is None else fun_labels\n    x0 = [(b[0] + b[1]) / 2 for b in bds] if x0 is None else x0\n    x0 = np.atleast_1d(x0)\n    xdim = x0.shape[0]\n    lb = np.atleast_1d([b[0] for b in bds])\n    ub = np.atleast_1d([b[1] for b in bds])\n    cmap = plt.get_cmap(cmap)\n\n    # Construct sliced inputs\n    xs = np.zeros((N, len(x_idx), xdim))\n    for i in range(len(x_idx)):\n        if random_walk:\n            # Make a random straight-line walk across d-cube\n            r0 = np.random.rand(xdim) * (ub - lb) + lb\n            r0[x_idx[i]] = lb[x_idx[i]]                     # Start slice at this lower bound\n            rf = np.random.rand(xdim) * (ub - lb) + lb\n            rf[x_idx[i]] = ub[x_idx[i]]                     # Slice up to this upper bound\n            xs[0, i, :] = r0\n            for k in range(1, N):\n                xs[k, i, :] = xs[k-1, i, :] + (rf-r0)/(N-1)\n        else:\n            # Otherwise, only slice one variable\n            for j in range(xdim):\n                if j == x_idx[i]:\n                    xs[:, i, j] = np.linspace(lb[x_idx[i]], ub[x_idx[i]], N)\n                else:\n                    xs[:, i, j] = x0[j]\n\n    # Compute function values and show ydim by xdim grid of subplots\n    ys = []\n    for func in funs:\n        y = func(xs)\n        if y.shape == (N, len(x_idx)):\n            y = y[..., np.newaxis]\n        ys.append(y)\n    c_intervals = np.linspace(0, 1, len(ys))\n\n    fig, axs = plt.subplots(len(y_idx), len(x_idx), sharex='col', sharey='row')\n    for i in range(len(y_idx)):\n        for j in range(len(x_idx)):\n            if len(y_idx) == 1:\n                ax = axs if len(x_idx) == 1 else axs[j]\n            elif len(x_idx) == 1:\n                ax = axs if len(y_idx) == 1 else axs[i]\n            else:\n                ax = axs[i, j]\n            x = xs[:, j, x_idx[j]]\n            for k in range(len(ys)):\n                y = ys[k][:, j, y_idx[i]]\n                ax.plot(x, y, ls='-', color=cmap(c_intervals[k]), label=fun_labels[k])\n            ylabel = ylabels[i] if j == 0 else ''\n            xlabel = xlabels[j] if i == len(y_idx) - 1 else ''\n            legend = (i == 0 and j == len(x_idx) - 1 and len(ys) &gt; 1)\n            ax_default(ax, xlabel, ylabel, legend=legend)\n    fig.set_size_inches(3 * len(x_idx), 3 * len(y_idx))\n    fig.tight_layout()\n\n    return fig, axs\n</code></pre>"},{"location":"reference/#uqtils.sobol_sa","title":"<code>sobol_sa(model, sampler, num_samples, qoi_idx=None, qoi_labels=None, param_labels=None, plot=False, verbose=True, cmap='viridis', compute_s2=False)</code>","text":"<p>Perform a global Sobol' sensitivity analysis.</p> PARAMETER DESCRIPTION <code>model</code> <p>callable as <code>y=model(x)</code>, with <code>y=(..., ydim)</code>, <code>x=(..., xdim)</code></p> <p> </p> <code>sampler</code> <p>callable as <code>x=sampler(shape)</code>, with <code>x=(*shape, xdim)</code></p> <p> </p> <code>num_samples</code> <p>number of samples</p> <p> TYPE: <code>int</code> </p> <code>qoi_idx</code> <p>list of indices of model output to report results for</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>qoi_labels</code> <p>list of labels for plotting QoIs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>param_labels</code> <p>list of labels for plotting input parameters</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>plot</code> <p>whether to plot bar/pie charts</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>whether to print <code>S1/ST/S2</code> results to the console</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>cmap</code> <p><code>str</code> specifier of <code>plt.colormap</code> for bar/pie charts</p> <p> TYPE: <code>str</code> DEFAULT: <code>'viridis'</code> </p> <code>compute_s2</code> <p>whether to compute the second order indices</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p><code>S1</code>, <code>[S2]</code>, <code>ST</code>, the first, second, and total order Sobol' indices</p> Source code in <code>src/uqtils/sobol.py</code> <pre><code>def sobol_sa(model, sampler, num_samples: int, qoi_idx: list[int] = None, qoi_labels: list[str] = None,\n             param_labels: list[str] = None, plot: bool = False, verbose: bool = True, cmap: str = 'viridis',\n             compute_s2: bool = False):\n    \"\"\"Perform a global Sobol' sensitivity analysis.\n\n    :param model: callable as `y=model(x)`, with `y=(..., ydim)`, `x=(..., xdim)`\n    :param sampler: callable as `x=sampler(shape)`, with `x=(*shape, xdim)`\n    :param num_samples: number of samples\n    :param qoi_idx: list of indices of model output to report results for\n    :param qoi_labels: list of labels for plotting QoIs\n    :param param_labels: list of labels for plotting input parameters\n    :param plot: whether to plot bar/pie charts\n    :param verbose: whether to print `S1/ST/S2` results to the console\n    :param cmap: `str` specifier of `plt.colormap` for bar/pie charts\n    :param compute_s2: whether to compute the second order indices\n    :return: `S1`, `[S2]`, `ST`, the first, second, and total order Sobol' indices\n    \"\"\"\n    # Get sample matrices (N, xdim)\n    A = sampler((num_samples,))\n    B = sampler((num_samples,))\n    xdim = A.shape[-1]\n    AB = np.tile(np.expand_dims(A, axis=-2), (1, xdim, 1))\n    BA = np.tile(np.expand_dims(B, axis=-2), (1, xdim, 1))\n    for i in range(xdim):\n        AB[:, i, i] = B[:, i]\n        BA[:, i, i] = A[:, i]\n\n    # Evaluate the model; (xdim+2)*N evaluations required\n    fA = model(A)       # (N, ydim)\n    fB = model(B)       # (N, ydim)\n    fAB = model(AB)     # (N, xdim, ydim)\n    fBA = model(BA)     # (N, xdim, ydim)\n    ydim = fA.shape[-1]\n\n    # Normalize model outputs to N(0, 1) for better stability\n    Y = np.concatenate((fA, fB, fAB.reshape((-1, ydim)), fBA.reshape((-1, ydim))), axis=0)\n    mu, std = np.mean(Y, axis=0), np.std(Y, axis=0)\n    fA = (fA - mu) / std\n    fB = (fB - mu) / std\n    fAB = (fAB - mu) / std\n    fBA = (fBA - mu) / std\n\n    # Compute sensitivity indices\n    vY = np.var(np.concatenate((fA, fB), axis=0), axis=0)   # (ydim,)\n    fA = np.expand_dims(fA, axis=-2)                        # (N, 1, ydim)\n    fB = np.expand_dims(fB, axis=-2)                        # (N, 1, ydim)\n    S1 = fB * (fAB - fA) / vY                               # (N, xdim, ydim)\n    ST = 0.5 * (fA - fAB)**2 / vY                           # (N, xdim, ydim)\n\n    # Second-order indices\n    if compute_s2:\n        Vij = np.expand_dims(fBA, axis=2) * np.expand_dims(fAB, axis=1) - \\\n              np.expand_dims(fA, axis=1) * np.expand_dims(fB, axis=1)   # (N, xdim, xdim, ydim)\n        si = fB * (fAB - fA)\n        Vi = np.expand_dims(si, axis=2)\n        Vj = np.expand_dims(si, axis=1)\n        S2 = (Vij - Vi - Vj) / vY                                       # (N, xdim, xdim, ydim)\n        S2_est = np.mean(S2, axis=0)\n        S2_se = np.sqrt(np.var(S2, axis=0) / num_samples)\n\n    # Get mean values and MC error\n    S1_est = np.mean(S1, axis=0)\n    S1_se = np.sqrt(np.var(S1, axis=0) / num_samples)\n    ST_est = np.mean(ST, axis=0)\n    ST_se = np.sqrt(np.var(ST, axis=0) / num_samples)\n\n    # Set defaults for qoi indices/labels\n    if qoi_idx is None:\n        qoi_idx = list(np.arange(ydim))\n    if qoi_labels is None:\n        qoi_labels = [f'QoI {i}' for i in range(len(qoi_idx))]\n    if param_labels is None:\n        param_labels = [f'x{i}' for i in range(xdim)]\n\n    # Print results\n    if verbose:\n        print(f'{\"QoI\":&gt;10} {\"Param\":&gt;10} {\"S1_mean\":&gt;10} {\"S1_err\":&gt;10} {\"ST_mean\":&gt;10} {\"ST_err\":&gt;10}')\n        for i in range(len(qoi_idx)):\n            for j in range(xdim):\n                q = qoi_idx[i]\n                print(f'{qoi_labels[i]:&gt;10} {param_labels[j]:&gt;10} {S1_est[j, q]: 10.3f} {S1_se[j, q]: 10.3f} '\n                      f'{ST_est[j, q]: 10.3f} {ST_se[j, q]: 10.3f}')\n\n        if compute_s2:\n            print(f'\\n{\"QoI\":&gt;10} {\"2nd-order\":&gt;20} {\"S2_mean\":&gt;10} {\"S2_err\":&gt;10}')\n            for i in range(len(qoi_idx)):\n                for j in range(xdim):\n                    for k in range(j+1, xdim):\n                        q = qoi_idx[i]\n                        print(f'{qoi_labels[i]:&gt;10} {\"(\"+param_labels[j]+\", \"+param_labels[k]+\")\":&gt;20} '\n                              f'{S2_est[j, k, q]: 10.3f} {S2_se[j, k, q]: 10.3f}')\n\n        S1_total = np.sum(S1_est, axis=0)       # (ydim,)\n        S2_total = np.zeros((ydim,))            # (ydim,)\n        if compute_s2:\n            for i in range(xdim):\n                for j in range(i+1, xdim):\n                    S2_total += S2_est[i, j, :]     # sum the upper diagonal\n        print(f'\\n{\"QoI\":&gt;10} {\"S1 total\":&gt;10} {\"S2 total\":&gt;10} {\"Higher order\":&gt;15}')\n        for i in range(len(qoi_idx)):\n            q = qoi_idx[i]\n            print(f'{qoi_labels[i]:&gt;10} {S1_total[q]: 10.3f} {S2_total[q]: 10.3f} '\n                  f'{1 - S1_total[q] - S2_total[q]: 15.3f}')\n\n    if plot:\n        # Plot bar chart of S1, ST\n        c = plt.get_cmap(cmap)\n        fig, axs = plt.subplots(1, len(qoi_idx))\n        for i in range(len(qoi_idx)):\n            ax = axs[i] if len(qoi_idx) &gt; 1 else axs\n            q = qoi_idx[i]\n            z = st.norm.ppf(1 - (1-0.95)/2)  # get z-score from N(0,1), assuming CLT at n&gt;30\n            x = np.arange(xdim)\n            width = 0.2\n            ax.bar(x - width / 2, S1_est[:, q], width, color=c(0.1), yerr=S1_se[:, q] * z,\n                   label=r'$S_1$', capsize=3, linewidth=1, edgecolor=[0, 0, 0])\n            ax.bar(x + width / 2, ST_est[:, q], width, color=c(0.9), yerr=ST_se[:, q] * z,\n                   label=r'$S_{T}$', capsize=3, linewidth=1, edgecolor=[0, 0, 0])\n            ax_default(ax, \"Model parameters\", \"Sobol' index\", legend=True)\n            ax.set_xticks(x, param_labels)\n            ax.set_ylim(bottom=0)\n            ax.set_title(qoi_labels[i])\n        fig.set_size_inches(4*len(qoi_idx), 4)\n        fig.tight_layout()\n        bar_chart = (fig, axs)\n\n        # Plot pie chart of S1, S2, higher-order\n        fig, axs = plt.subplots(1, len(qoi_idx))\n        for i in range(len(qoi_idx)):\n            ax = axs[i] if len(qoi_idx) &gt; 1 else axs\n            q = qoi_idx[i]\n            values = []\n            labels = []\n            s12_other = 0\n            thresh = 0.05    # Only show indices with &gt; 5% effect\n            for j in range(xdim):\n                if S1_est[j, q] &gt; thresh:\n                    values.append(S1_est[j, q])\n                    labels.append(param_labels[j])\n                else:\n                    s12_other += max(S1_est[j, q], 0)\n\n            if compute_s2:\n                for j in range(xdim):\n                    for k in range(j+1, xdim):\n                        if S2_est[j, k, q] &gt; thresh:\n                            values.append(S2_est[j, k, q])\n                            labels.append(\"(\"+param_labels[j]+\", \"+param_labels[k]+\")\")\n                        else:\n                            s12_other += max(S2_est[j, k, q], 0)\n\n            values.append(max(s12_other, 0))\n            labels.append(r'Other $S_1$, $S_2$')\n            s_higher = max(1 - np.sum(values), 0)\n            values.append(s_higher)\n            labels.append(r'Higher order')\n\n            # Adjust labels to show percents, sort by value, and threshold small values for plotting\n            labels = [f\"{label}, {100*values[i]:.1f}%\" if values[i] &gt; thresh else\n                      f\"{label}, &lt;{max(0.5, round(100*values[i]))}%\" for i, label in enumerate(labels)]\n            values = [val if val &gt; thresh else max(0.02, val) for val in values]\n            labels, values = list(zip(*sorted(zip(labels, values), reverse=True, key=lambda ele: ele[1])))\n\n            # Generate pie chart\n            colors = c(np.linspace(0, 1, len(values)-2))\n            gray_idx = [idx for idx, label in enumerate(labels) if label.startswith('Higher') or\n                        label.startswith('Other')]\n            pie_colors = np.empty((len(values), 4))\n            c_idx = 0\n            for idx in range(len(values)):\n                if idx in gray_idx:\n                    pie_colors[idx, :] = [0.7, 0.7, 0.7, 1]\n                else:\n                    pie_colors[idx, :] = colors[c_idx, :]\n                    c_idx += 1\n            radius = 2\n            wedges, label_boxes = ax.pie(values, colors=pie_colors, radius=radius, startangle=270,\n                                         shadow=True, counterclock=False, frame=True,\n                                         wedgeprops=dict(linewidth=1.5, width=0.6*radius, edgecolor='w'),\n                                         textprops={'color': [0, 0, 0, 1], 'fontsize': 10, 'family': 'serif'})\n            kw = dict(arrowprops=dict(arrowstyle=\"-\"), zorder=0, va=\"center\", fontsize=9, family='serif',\n                      bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0))\n\n            # Put annotations with arrows to each wedge (coordinate system is relative to center of pie)\n            for j, wed in enumerate(wedges):\n                ang = (wed.theta2 - wed.theta1) / 2. + wed.theta1\n                x = radius * np.cos(np.deg2rad(ang))\n                y = radius * np.sin(np.deg2rad(ang))\n                ax.scatter(x, y, s=10, c='k')\n                kw[\"horizontalalignment\"] = \"right\" if int(np.sign(x)) == -1 else \"left\"\n                kw[\"arrowprops\"].update({\"connectionstyle\": f\"angle,angleA=0,angleB={ang}\"})\n                y_offset = 0.2 if j == len(labels) - 1 else 0\n                ax.annotate(labels[j], xy=(x, y), xytext=((radius+0.2)*np.sign(x), 1.3*y - y_offset), **kw)\n            ax.set(aspect=\"equal\")\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            ax.spines['left'].set_visible(False)\n            ax.spines['bottom'].set_visible(False)\n            ax.get_yaxis().set_ticks([])\n            ax.get_xaxis().set_ticks([])\n            ax.set_title(qoi_labels[i])\n        fig.set_size_inches(3*radius*len(qoi_idx), 2.5*radius)\n        fig.tight_layout()\n        fig.subplots_adjust(left=0.15, right=0.75)\n        pie_chart = (fig, axs)\n\n    if compute_s2:\n        ret = (S1, S2, ST)\n    else:\n        ret = (S1, ST)\n    if plot:\n        ret = ret + (bar_chart, pie_chart)\n    return ret\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> uqtils</li> <li> gradient</li> <li> mcmc</li> <li> plots</li> <li> sobol</li> </ul>"},{"location":"reference/gradient/","title":"gradient","text":""},{"location":"reference/gradient/#uqtils.gradient","title":"<code>uqtils.gradient</code>","text":"<p>Module for vectorized finite-difference gradient approximations.</p> <p>Includes:</p> <ul> <li><code>approx_jac</code> - vectorized Jacobian approximation</li> <li><code>approx_hess</code> - vectorized Hessian approximation</li> </ul>"},{"location":"reference/gradient/#uqtils.gradient.approx_hess","title":"<code>approx_hess(func, theta, pert=0.01)</code>","text":"<p>Approximate Hessian of <code>func</code> at a specified <code>theta</code> location using finite difference approximation.</p> PARAMETER DESCRIPTION <code>func</code> <p>expects to be called as <code>func(theta) -&gt; (..., y_dim)</code></p> <p> </p> <code>theta</code> <p><code>(..., theta_dim)</code>, points to linearize model about</p> <p> TYPE: <code>Array</code> </p> <code>pert</code> <p>perturbation percent for approximate partial derivatives</p> <p> DEFAULT: <code>0.01</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(..., y_dim, theta_dim, theta_dim)</code>, the approximate Hessian <code>(theta_dim, theta_dim)</code> at all locations <code>(...,)</code> for vector-valued function of dimension <code>y_dim</code></p> Source code in <code>src/uqtils/gradient.py</code> <pre><code>def approx_hess(func, theta: Array, pert=0.01) -&gt; np.ndarray:\n    \"\"\"Approximate Hessian of `func` at a specified `theta` location using finite difference approximation.\n\n    :param func: expects to be called as `func(theta) -&gt; (..., y_dim)`\n    :param theta: `(..., theta_dim)`, points to linearize model about\n    :param pert: perturbation percent for approximate partial derivatives\n    :returns H: `(..., y_dim, theta_dim, theta_dim)`, the approximate Hessian `(theta_dim, theta_dim)` at all locations\n                `(...,)` for vector-valued function of dimension `y_dim`\n    \"\"\"\n    theta = np.atleast_1d(theta)\n    shape = theta.shape[:-1]                # (...,)\n    theta_dim = theta.shape[-1]             # Number of parameters\n    dtheta = pert * np.abs(theta)\n\n    # Make sure dtheta is not 0 anywhere\n    for i in range(theta_dim):\n        zero_idx = np.isclose(dtheta[..., i], 0)\n        if np.any(zero_idx):\n            subs_dtheta = pert * np.abs(np.mean(theta[..., i]))\n            if np.isclose(subs_dtheta, 0):\n                subs_dtheta = pert\n            dtheta[zero_idx, i] = subs_dtheta\n\n    # Return the Hessians (..., y_dim, theta_dim, theta_dim)\n    y_dim, H = None, None\n\n    for i in range(theta_dim):\n        for j in range(i, theta_dim):\n            # Allocate space at 4 grid points (n1=-1, p1=+1)\n            theta_n1_n1 = np.copy(theta)\n            theta_p1_p1 = np.copy(theta)\n            theta_n1_p1 = np.copy(theta)\n            theta_p1_n1 = np.copy(theta)\n\n            # Perturbations to theta in each direction\n            theta_n1_n1[..., i] -= dtheta[..., i]\n            theta_n1_n1[..., j] -= dtheta[..., j]\n            f_n1_n1 = func(theta_n1_n1)\n\n            theta_p1_p1[..., i] += dtheta[..., i]\n            theta_p1_p1[..., j] += dtheta[..., j]\n            f_p1_p1 = func(theta_p1_p1)\n\n            theta_n1_p1[..., i] -= dtheta[..., i]\n            theta_n1_p1[..., j] += dtheta[..., j]\n            f_n1_p1 = func(theta_n1_p1)\n\n            theta_p1_n1[..., i] += dtheta[..., i]\n            theta_p1_n1[..., j] -= dtheta[..., j]\n            f_p1_n1 = func(theta_p1_n1)\n\n            if H is None:\n                y_dim = f_p1_n1.shape[-1]\n                H = np.empty(shape + (y_dim, theta_dim, theta_dim))\n\n            res = (f_n1_n1 + f_p1_p1 - f_n1_p1 - f_p1_n1) / np.expand_dims(4 * dtheta[..., i] * dtheta[..., j],\n                                                                           axis=-1)\n            H[..., i, j] = res\n            H[..., j, i] = res\n\n    if y_dim == 1:\n        H = np.squeeze(H, axis=-3)\n        if theta_dim == 1:\n            H = np.squeeze(H, axis=(-1, -2))\n    return np.atleast_1d(H)\n</code></pre>"},{"location":"reference/gradient/#uqtils.gradient.approx_jac","title":"<code>approx_jac(func, theta, pert=0.01)</code>","text":"<p>Approximate Jacobian of <code>func</code> at a specified <code>theta</code> location using finite difference approximation.</p> PARAMETER DESCRIPTION <code>func</code> <p>expects to be called as <code>func(theta) -&gt; (..., y_dim)</code></p> <p> </p> <code>theta</code> <p><code>(..., theta_dim)</code>, points to linearize model about</p> <p> TYPE: <code>Array</code> </p> <code>pert</code> <p>perturbation percent for approximate partial derivatives</p> <p> DEFAULT: <code>0.01</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(..., y_dim, theta_dim)</code>, the approximate Jacobian <code>(y_dim, theta_dim)</code> at all locations <code>(...)</code></p> Source code in <code>src/uqtils/gradient.py</code> <pre><code>def approx_jac(func, theta: Array, pert=0.01) -&gt; np.ndarray:\n    \"\"\"Approximate Jacobian of `func` at a specified `theta` location using finite difference approximation.\n\n    :param func: expects to be called as `func(theta) -&gt; (..., y_dim)`\n    :param theta: `(..., theta_dim)`, points to linearize model about\n    :param pert: perturbation percent for approximate partial derivatives\n    :returns J: `(..., y_dim, theta_dim)`, the approximate Jacobian `(y_dim, theta_dim)` at all locations `(...)`\n    \"\"\"\n    theta = np.atleast_1d(theta)\n    shape = theta.shape[:-1]                # (...,)\n    theta_dim = theta.shape[-1]             # Number of parameters\n    dtheta = pert * np.abs(theta)\n\n    # Make sure dtheta is not 0 anywhere\n    for i in range(theta_dim):\n        zero_idx = np.isclose(dtheta[..., i], 0)\n        if np.any(zero_idx):\n            subs_dtheta = pert * np.abs(np.mean(theta[..., i]))\n            if np.isclose(subs_dtheta, 0):\n                subs_dtheta = pert\n            dtheta[zero_idx, i] = subs_dtheta\n\n    # Return the Jacobians (..., y_dim, theta_dim)\n    J, y_dim = None, None\n\n    for i in range(theta_dim):\n        theta_n1 = np.copy(theta)\n        theta_p1 = np.copy(theta)\n\n        # Perturbations to theta\n        theta_n1[..., i] -= dtheta[..., i]\n        theta_p1[..., i] += dtheta[..., i]\n        f_n1 = func(theta_n1)\n        f_p1 = func(theta_p1)\n\n        if J is None:\n            y_dim = f_p1.shape[-1]\n            J = np.empty(shape + (y_dim, theta_dim))\n\n        J[..., i] = (f_p1 - f_n1) / np.expand_dims(2 * dtheta[..., i], axis=-1)\n\n    if y_dim == 1:\n        J = np.squeeze(J, axis=-2)\n        if theta_dim == 1:\n            J = np.squeeze(J, axis=-1)\n    return np.atleast_1d(J)\n</code></pre>"},{"location":"reference/mcmc/","title":"mcmc","text":""},{"location":"reference/mcmc/#uqtils.mcmc","title":"<code>uqtils.mcmc</code>","text":"<p>Module for Markov-Chain Monte Carlo routines.</p> <p>Includes:</p> <ul> <li><code>normal_pdf</code> - vectorized Gaussian pdf evaluation</li> <li><code>normal_sample</code> - vectorized Gaussian sampling</li> <li><code>is_positive_definite</code> - whether a matrix is positive semi-definite</li> <li><code>nearest_positive_definite</code> - finds the nearest PSD matrix</li> <li><code>dram</code> - Delayed rejection adaptive Metropolis-Hastings MCMC</li> <li><code>autocorrelation</code> - computes the autocorrelation of a set of samples</li> </ul>"},{"location":"reference/mcmc/#uqtils.mcmc.autocorrelation","title":"<code>autocorrelation(samples, maxlag=100, step=1)</code>","text":"<p>Compute the auto-correlation of a set of samples.</p> PARAMETER DESCRIPTION <code>samples</code> <p><code>(niter, nwalk, ndim)</code> samples returned from <code>dram</code> or a similar MCMC routine</p> <p> </p> <code>maxlag</code> <p>maximum distance to compute the correlation for</p> <p> DEFAULT: <code>100</code> </p> <code>step</code> <p>step between distances from 0 to <code>maxlag</code> for which to compute the correlations</p> <p> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <p>lags, autos, tau, ess - the lag times, auto-correlations, integrated auto-correlation, and effective sample sizes</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def autocorrelation(samples, maxlag=100, step=1):\n    \"\"\"Compute the auto-correlation of a set of samples.\n\n    :param samples: `(niter, nwalk, ndim)` samples returned from `dram` or a similar MCMC routine\n    :param maxlag: maximum distance to compute the correlation for\n    :param step: step between distances from 0 to `maxlag` for which to compute the correlations\n    :returns: lags, autos, tau, ess - the lag times, auto-correlations, integrated auto-correlation,\n              and effective sample sizes\n    \"\"\"\n    niter, nwalk, ndim = samples.shape\n    mean = np.mean(samples, axis=0)\n    var = np.sum((samples - mean[np.newaxis, ...]) ** 2, axis=0)\n\n    lags = np.arange(0, maxlag, step)\n    autos = np.zeros((len(lags), nwalk, ndim))\n    for zz, lag in enumerate(lags):\n        # compute the covariance between all samples *lag apart*\n        for ii in range(niter - lag):\n            autos[zz, ...] += (samples[ii, ...] - mean) * (samples[ii + lag, ...] - mean)\n        autos[zz, ...] /= var\n    tau = 1 + 2 * np.sum(autos, axis=0)     # Integrated auto-correlation\n    ess = niter / tau                       # Effective sample size\n    return lags, autos, tau, ess\n</code></pre>"},{"location":"reference/mcmc/#uqtils.mcmc.dram","title":"<code>dram(logpdf, x0, niter, cov0=None, gamma=0.5, eps=1e-06, adapt_after=100, adapt_interval=10, delayed=True, progress=True, filename=None)</code>","text":"<p>Delayed adaptive metropolis-hastings MCMC with a Gaussian proposal.</p> PARAMETER DESCRIPTION <code>logpdf</code> <p>log PDF function of target distribution</p> <p> </p> <code>x0</code> <p><code>(nwalkers, ndim)</code> initial parameter samples, ignored if samples exist in <code>filename</code></p> <p> </p> <code>cov0</code> <p><code>(ndim, ndim)</code> the initial proposal covariance, defaults to identity or <code>cov</code> value in filename</p> <p> DEFAULT: <code>None</code> </p> <code>niter</code> <p>number of iterations</p> <p> </p> <code>gamma</code> <p>scale factor for the covariance matrix for delayed rejection step</p> <p> DEFAULT: <code>0.5</code> </p> <code>eps</code> <p>small constant for making sure covariance is well-conditioned</p> <p> DEFAULT: <code>1e-06</code> </p> <code>adapt_after</code> <p>the number of iterations before covariance adaptation begins (ignored if &lt;=0)</p> <p> DEFAULT: <code>100</code> </p> <code>adapt_interval</code> <p>the number of iterations between each covariance adaptation (ignored if <code>adapt_after&lt;=0</code>)</p> <p> DEFAULT: <code>10</code> </p> <code>delayed</code> <p>whether to try to sample again after first rejection</p> <p> DEFAULT: <code>True</code> </p> <code>progress</code> <p>whether to display progress of the sampler</p> <p> DEFAULT: <code>True</code> </p> <code>filename</code> <p>if specified, an hdf5 file to save results to. If the file already has dram results, the new samples will be appended. Follows the same format as the <code>emcee</code> library</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p><code>samples, log_pdf, acceptance</code> - <code>(niter, nwalkers, ndim)</code> samples of the target distribution, the logpdf values at these locations, and the cumulative number of accepted samples per walker</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def dram(logpdf, x0, niter, cov0=None, gamma=0.5, eps=1e-6, adapt_after=100, adapt_interval=10,\n         delayed=True, progress=True, filename=None):\n    \"\"\"Delayed adaptive metropolis-hastings MCMC with a Gaussian proposal.\n\n    :param logpdf: log PDF function of target distribution\n    :param x0: `(nwalkers, ndim)` initial parameter samples, ignored if samples exist in `filename`\n    :param cov0: `(ndim, ndim)` the initial proposal covariance, defaults to identity or `cov` value in filename\n    :param niter: number of iterations\n    :param gamma: scale factor for the covariance matrix for delayed rejection step\n    :param eps: small constant for making sure covariance is well-conditioned\n    :param adapt_after: the number of iterations before covariance adaptation begins (ignored if &lt;=0)\n    :param adapt_interval: the number of iterations between each covariance adaptation (ignored if `adapt_after&lt;=0`)\n    :param delayed: whether to try to sample again after first rejection\n    :param progress: whether to display progress of the sampler\n    :param filename: if specified, an hdf5 file to save results to. If the file already has dram results, the new\n                     samples will be appended. Follows the same format as the `emcee` library\n    :returns: `samples, log_pdf, acceptance` - `(niter, nwalkers, ndim)` samples of the target distribution, the logpdf\n              values at these locations, and the cumulative number of accepted samples per walker\n    \"\"\"\n    # Override x0, cov0 if filename already has samples\n    try:\n        if filename is not None:\n            with h5py.File(filename, 'a') as fd:\n                group = fd.get('mcmc', None)\n                if group is not None:\n                    x0 = group['chain'][-1, ...]\n                    if cov0 is None:\n                        cov0 = np.array(group['cov'])  # only override if cov0 is not passed in\n                    niter += 1\n    except Exception as e:\n        warnings.warn(str(e))\n\n    # Initialize\n    x0 = np.atleast_2d(x0)\n    nwalk, ndim = x0.shape\n    cov0 = np.eye(ndim) if cov0 is None else cov0\n    sd = (2.4**2/ndim)\n    curr_cov = np.broadcast_to(cov0, (nwalk, ndim, ndim)).copy().astype(x0.dtype)\n    curr_chol = np.linalg.cholesky(curr_cov)\n    adapt_cov = curr_cov.copy()  # adaptive covariance\n    curr_mean = x0\n    curr_loc_logpdf = logpdf(x0)\n    samples = np.empty((niter, nwalk, ndim), dtype=x0.dtype)\n    log_pdf = np.empty((niter, nwalk), dtype=x0.dtype)\n    accepted = np.zeros((nwalk,), dtype=x0.dtype)\n    samples[0, ...] = x0\n    log_pdf[0, ...] = curr_loc_logpdf\n\n    def accept_first(curr_log, prop_log):\n        with np.errstate(over='ignore'):\n            # Overflow values go to -&gt; infty, so they will always get accepted\n            ret = np.minimum(1.0, np.exp(prop_log - curr_log))\n        return ret\n\n    # Main sample loop\n    iterable = tqdm.tqdm(range(niter-1)) if progress else range(niter-1)\n    # --8&lt;-- [start:dram]\n    for i in iterable:\n        # Propose sample\n        x1 = samples[i, ...]\n        y1 = normal_sample(x1, curr_chol, sqrt=True)    # (nwalkers, ndim)\n        x1_log = curr_loc_logpdf\n        y1_log = logpdf(y1)\n\n        # Compute first acceptance\n        with np.errstate(invalid='ignore'):\n            a1 = y1_log - x1_log                        # (nwalkers,)\n        a1_idx = a1 &gt; 0\n        a1_idx |= np.log(np.random.rand(nwalk)) &lt; a1\n        samples[i + 1, a1_idx, :] = y1[a1_idx, :]\n        samples[i + 1, ~a1_idx, :] = x1[~a1_idx, :]\n        curr_loc_logpdf[a1_idx] = y1_log[a1_idx]\n        accepted[a1_idx] += 1\n\n        # Second level proposal\n        if delayed and np.any(~a1_idx):\n            y2 = normal_sample(x1[~a1_idx, :], curr_chol[~a1_idx, ...] * np.sqrt(gamma), sqrt=True)\n            y2_log = logpdf(y2)\n            with ((np.errstate(divide='ignore', invalid='ignore'))):\n                # If a(y2, y1)=1, then log(1-a(y2,y1)) -&gt; -infty and a2 -&gt; 0\n                frac_1 = y2_log - x1_log[~a1_idx]\n                frac_2 = (normal_pdf(y1[~a1_idx, :], y2, curr_cov[~a1_idx, ...], logpdf=True) -\n                          normal_pdf(y1[~a1_idx, :], x1[~a1_idx, :], curr_cov[~a1_idx, ...], logpdf=True))\n                frac_3 = (np.log(1 - accept_first(y2_log, y1_log[~a1_idx])) -\n                          np.log(1 - np.minimum(1.0, np.exp(a1[~a1_idx]))))\n                a2 = frac_1 + frac_2 + frac_3\n            a2_idx = a2 &gt; 0\n            a2_idx |= np.log(np.random.rand(a2.shape[0])) &lt; a2\n\n            sample_a2_idx = np.where(~a1_idx)[0][a2_idx]  # Indices that were False the 1st time, then true the 2nd\n            samples[i + 1, sample_a2_idx, :] = y2[a2_idx, :]\n            curr_loc_logpdf[sample_a2_idx] = y2_log[a2_idx]\n            accepted[sample_a2_idx] += 1\n\n        log_pdf[i+1, ...] = curr_loc_logpdf\n\n        # Update the sample mean and cov every iteration\n        if adapt_after &gt; 0:\n            k = i + 1\n            last_mean = curr_mean.copy()\n            curr_mean = (1/(k+1)) * samples[k, ...] + (k/(k+1))*last_mean\n            mult = (np.eye(ndim) * eps + k * last_mean[..., np.newaxis] @ last_mean[..., np.newaxis, :] -\n                    (k + 1) * curr_mean[..., np.newaxis] @ curr_mean[..., np.newaxis, :] +\n                    samples[k, ..., np.newaxis] @ samples[k, ..., np.newaxis, :])\n            adapt_cov = ((k - 1) / k) * adapt_cov + (sd / k) * mult\n\n            if k &gt; adapt_after and k % adapt_interval == 0:\n                try:\n                    curr_chol[:] = np.linalg.cholesky(adapt_cov)\n                    curr_cov[:] = adapt_cov[:]\n                except np.linalg.LinAlgError:\n                    warnings.warn(f\"Non-PSD matrix at k={k}. Ignoring...\")\n    # --8&lt;-- [end:dram]\n\n    try:\n        if filename is not None:\n            with h5py.File(filename, 'a') as fd:\n                group = fd.get('mcmc', None)\n                if group is not None:\n                    samples = np.concatenate((group['chain'], samples[1:, ...]), axis=0)\n                    log_pdf = np.concatenate((group['log_pdf'], log_pdf[1:, ...]), axis=0)\n                    accepted += group['accepted']\n                    del group['chain']\n                    del group['log_pdf']\n                    del group['accepted']\n                    del group['cov']\n                fd.create_dataset('mcmc/chain', data=samples)\n                fd.create_dataset('mcmc/log_pdf', data=log_pdf)\n                fd.create_dataset('mcmc/accepted', data=accepted)\n                fd.create_dataset('mcmc/cov', data=curr_cov)\n    except Exception as e:\n        warnings.warn(str(e))\n\n    return samples, log_pdf, accepted\n</code></pre>"},{"location":"reference/mcmc/#uqtils.mcmc.is_positive_definite","title":"<code>is_positive_definite(A)</code>","text":"<p>Returns true when input is positive-definite, via Cholesky.</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def is_positive_definite(A):\n    \"\"\"Returns true when input is positive-definite, via Cholesky.\"\"\"\n    try:\n        _ = np.linalg.cholesky(A)\n        return True\n    except np.linalg.LinAlgError:\n        return False\n</code></pre>"},{"location":"reference/mcmc/#uqtils.mcmc.nearest_positive_definite","title":"<code>nearest_positive_definite(A)</code>","text":"<p>Find the nearest positive-definite matrix to input.</p> <p>A Python port of John D'Errico's <code>nearestSPD</code> MATLAB code [1], which credits [2]. [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\", 1988</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def nearest_positive_definite(A):\n    \"\"\"Find the nearest positive-definite matrix to input.\n\n    A Python port of John D'Errico's `nearestSPD` MATLAB code [1], which credits [2].\n    [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd\n    [2] N.J. Higham, \"Computing a nearest symmetric positive semidefinite matrix\", 1988\n    \"\"\"\n    B = (A + A.T) / 2\n    _, s, V = np.linalg.svd(B)\n    H = np.dot(V.T, np.dot(np.diag(s), V))\n    A2 = (B + H) / 2\n    A3 = (A2 + A2.T) / 2\n    if is_positive_definite(A3):\n        return A3\n    spacing = np.spacing(np.linalg.norm(A))\n    # The above is different from [1]. It appears that MATLAB's `chol` Cholesky\n    # decomposition will accept matrixes with exactly 0-eigenvalue, whereas\n    # Numpy's will not. So where [1] uses `eps(mineig)` (where `eps` is Matlab\n    # for `np.spacing`), we use the above definition. CAVEAT: our `spacing`\n    # will be much larger than [1]'s `eps(mineig)`, since `mineig` is usually on\n    # the order of 1e-16, and `eps(1e-16)` is on the order of 1e-34, whereas\n    # `spacing` will, for Gaussian random matrixes of small dimension, be on\n    # othe order of 1e-16. In practice, both ways converge, as the unit test\n    # below suggests.\n    eye = np.eye(A.shape[0])\n    k = 1\n    while not is_positive_definite(A3):\n        mineig = np.min(np.real(np.linalg.eigvals(A3)))\n        A3 += eye * (-mineig * k ** 2 + spacing)\n        k += 1\n\n    return A3\n</code></pre>"},{"location":"reference/mcmc/#uqtils.mcmc.normal_pdf","title":"<code>normal_pdf(x, mean, cov, logpdf=False)</code>","text":"<p>Compute the Gaussian pdf at each <code>x</code> location (pretty much however you want).</p> PARAMETER DESCRIPTION <code>x</code> <p><code>(..., dim)</code>, the locations to evaluate the pdf at</p> <p> TYPE: <code>Array</code> </p> <code>mean</code> <p><code>(..., dim)</code>, expected values, where dim is the random variable dimension</p> <p> TYPE: <code>Array</code> </p> <code>cov</code> <p><code>(..., dim, dim)</code>, covariance matrices</p> <p> TYPE: <code>Array</code> </p> <code>logpdf</code> <p>whether to return the logpdf instead</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(...,)</code> the pdf values at <code>x</code></p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def normal_pdf(x: Array, mean: Array, cov: Array, logpdf: bool = False) -&gt; np.ndarray:\n    \"\"\"Compute the Gaussian pdf at each `x` location (pretty much however you want).\n\n    :param x: `(..., dim)`, the locations to evaluate the pdf at\n    :param mean: `(..., dim)`, expected values, where dim is the random variable dimension\n    :param cov: `(..., dim, dim)`, covariance matrices\n    :param logpdf: whether to return the logpdf instead\n    :returns: `(...,)` the pdf values at `x`\n    \"\"\"\n    x = np.atleast_1d(x)\n    mean = np.atleast_1d(mean)\n    cov = np.atleast_2d(cov)\n    dim = cov.shape[-1]\n\n    preexp = 1 / ((2*np.pi)**(dim/2) * np.linalg.det(cov)**(1/2))\n    diff = x - mean\n    diff_col = np.expand_dims(diff, axis=-1)    # (..., dim, 1)\n    diff_row = np.expand_dims(diff, axis=-2)    # (..., 1, dim)\n    inexp = np.squeeze(diff_row @ np.linalg.inv(cov) @ diff_col, axis=(-1, -2))\n\n    pdf = np.log(preexp) - 0.5 * inexp if logpdf else preexp * np.exp(-0.5 * inexp)\n\n    return pdf\n</code></pre>"},{"location":"reference/mcmc/#uqtils.mcmc.normal_sample","title":"<code>normal_sample(mean, cov, size=(), sqrt=False)</code>","text":"<p>Generic batch sample multivariate normal distributions (pretty much however you want).</p> <p>Note</p> <p>The provided <code>mean</code> and <code>cov</code> should match along the last dimension, that is the dimension of the random variables to sample. If you want to sample a 1d Gaussian, then you can specify both the mean and covariance as scalars. However, as long as the mean and covariance are broadcastable in size, then you can use this function however you want, (i.e. sample many multivariate distributions at once, all with different means and covariances, etc., just get creative)</p> PARAMETER DESCRIPTION <code>mean</code> <p><code>(..., dim)</code>, expected values, where <code>dim</code> is the random variable dimension</p> <p> TYPE: <code>Array</code> </p> <code>cov</code> <p><code>(..., dim, dim)</code>, covariance matrices (or the sqrt(cov) if <code>sqrt=True</code>)</p> <p> TYPE: <code>Array</code> </p> <code>size</code> <p>shape of additional samples</p> <p> TYPE: <code>tuple | int</code> DEFAULT: <code>()</code> </p> <code>sqrt</code> <p>whether <code>cov</code> was passed in already as the <code>sqrt(cov)</code> via cholesky decomposition</p> <p> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p><code>(*size, ..., dim)</code>, samples from multivariate distributions</p> Source code in <code>src/uqtils/mcmc.py</code> <pre><code>def normal_sample(mean: Array, cov: Array, size: tuple | int = (), sqrt=False) -&gt; np.ndarray:\n    \"\"\"Generic batch sample multivariate normal distributions (pretty much however you want).\n\n    !!! Note\n        The provided `mean` and `cov` should match along the last dimension, that is the dimension of the random\n        variables to sample. If you want to sample a 1d Gaussian, then you can specify both the mean and covariance\n        as scalars. However, as long as the mean and covariance are broadcastable in size, then you can use this\n        function however you want, (i.e. sample many multivariate distributions at once, all with different means\n        and covariances, etc., just get creative)\n\n    :param mean: `(..., dim)`, expected values, where `dim` is the random variable dimension\n    :param cov: `(..., dim, dim)`, covariance matrices (or the sqrt(cov) if `sqrt=True`)\n    :param size: shape of additional samples\n    :param sqrt: whether `cov` was passed in already as the `sqrt(cov)` via cholesky decomposition\n    :returns samples: `(*size, ..., dim)`, samples from multivariate distributions\n    \"\"\"\n    mean = np.atleast_1d(mean)\n    cov = np.atleast_2d(cov)\n    sqrt_cov = cov if sqrt else np.linalg.cholesky(cov)\n\n    if isinstance(size, int):\n        size = (size, )\n    shape = size + np.broadcast_shapes(mean.shape, cov.shape[:-1])\n    x_normal = np.random.standard_normal((*shape, 1)).astype(mean.dtype)\n    samples = np.squeeze(sqrt_cov @ x_normal, axis=-1) + mean\n    return samples\n</code></pre>"},{"location":"reference/plots/","title":"plots","text":""},{"location":"reference/plots/#uqtils.plots","title":"<code>uqtils.plots</code>","text":"<p>Module for plotting utilities.</p> <p>Includes:</p> <ul> <li><code>ax_default</code> - Nice default plt formatting for x-y data</li> <li><code>plot_slice</code> - Plots a grid of 1d slices of a multivariate function</li> <li><code>ndscatter</code> - Plots a grid of 1d and 2d marginals in a \"corner plot\" for n-dimensional data (especially for MCMC)</li> </ul>"},{"location":"reference/plots/#uqtils.plots.ax_default","title":"<code>ax_default(ax, xlabel='', ylabel='', legend=None, cmap='tab10')</code>","text":"<p>Nice default plt formatting for plotting X-Y data.</p> PARAMETER DESCRIPTION <code>ax</code> <p>the axes to apply these settings to</p> <p> TYPE: <code>Axes</code> </p> <code>xlabel</code> <p>the xlabel to set for <code>ax</code></p> <p> DEFAULT: <code>''</code> </p> <code>ylabel</code> <p>the ylabel to set for <code>ax</code></p> <p> DEFAULT: <code>''</code> </p> <code>legend</code> <p>will display a legend if bool(legend) is truthy, can pass a dict of legend kwargs here (optional)</p> <p> DEFAULT: <code>None</code> </p> <code>cmap</code> <p>colormap to use for cycling</p> <p> DEFAULT: <code>'tab10'</code> </p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def ax_default(ax: plt.Axes, xlabel='', ylabel='', legend=None, cmap='tab10'):\n    \"\"\"Nice default plt formatting for plotting X-Y data.\n\n    :param ax: the axes to apply these settings to\n    :param xlabel: the xlabel to set for `ax`\n    :param ylabel: the ylabel to set for `ax`\n    :param legend: will display a legend if bool(legend) is truthy, can pass a dict of legend kwargs here (optional)\n    :param cmap: colormap to use for cycling\n    \"\"\"\n    default_leg = {'fancybox': True, 'facecolor': 'white', 'framealpha': 1, 'loc': 'best', 'edgecolor': 'k'}\n    leg_use = legend if isinstance(legend, dict) else default_leg\n    for key, val in default_leg.items():\n        if key not in leg_use:\n            leg_use[key] = val\n\n    ax.set_prop_cycle(_get_cycle(cmap))\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.tick_params(axis='both', which='both', direction='in')\n    if legend:\n        leg = ax.legend(**leg_use)\n        return leg\n</code></pre>"},{"location":"reference/plots/#uqtils.plots.ndscatter","title":"<code>ndscatter(samples, labels=None, tick_fmts=None, plot1d=None, plot2d='scatter', cmap='viridis', bins=20, cmin=0, z=None, cb_label=None, cb_norm='linear', subplot_size=3, cov_overlay=None)</code>","text":"<p>Triangle scatter plots of n-dimensional samples.</p> <p>Warning</p> <p>Best for <code>dim &lt; 10</code>. You can shrink the <code>subplot_size</code> to assist graphics loading time.</p> PARAMETER DESCRIPTION <code>samples</code> <p><code>(N, dim)</code> samples to plot</p> <p> TYPE: <code>ndarray</code> </p> <code>labels</code> <p>list of axis labels of length <code>dim</code></p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>tick_fmts</code> <p>list of str.format() specifiers for ticks, e.g <code>['{x: ^10.2f}', ...]</code>, of length <code>dim</code></p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>plot1d</code> <p>'hist' or 'kde' for 1d marginals, defaults to plot2d if None</p> <p> TYPE: <code>Literal['kde', 'hist']</code> DEFAULT: <code>None</code> </p> <code>plot2d</code> <p>'hist' for 2d hist plot, 'kde' for kernel density estimation, 'hex', or 'scatter' (default)</p> <p> TYPE: <code>Literal['scatter', 'kde', 'hist', 'hex']</code> DEFAULT: <code>'scatter'</code> </p> <code>cmap</code> <p>the matplotlib string specifier of a colormap</p> <p> DEFAULT: <code>'viridis'</code> </p> <code>bins</code> <p>number of bins in each dimension for histogram marginals</p> <p> DEFAULT: <code>20</code> </p> <code>cmin</code> <p>the minimum bin count below which the bins are not displayed</p> <p> DEFAULT: <code>0</code> </p> <code>z</code> <p><code>(N,)</code> a performance metric corresponding to <code>samples</code>, used to color code the scatter plot if provided</p> <p> TYPE: <code>ndarray</code> DEFAULT: <code>None</code> </p> <code>cb_label</code> <p>label for color bar (if <code>z</code> is provided)</p> <p> DEFAULT: <code>None</code> </p> <code>cb_norm</code> <p><code>str</code> or <code>plt.colors.Normalize</code>, normalization method for plotting <code>z</code> on scatter plot</p> <p> DEFAULT: <code>'linear'</code> </p> <code>subplot_size</code> <p>size in inches of a single 2d marginal subplot</p> <p> DEFAULT: <code>3</code> </p> <code>cov_overlay</code> <p><code>(ndim, ndim)</code> a covariance matrix to overlay as a Gaussian kde over the samples</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p>the <code>plt</code> Figure and Axes objects, (returns an additional <code>cb_fig, cb_ax</code> if <code>z</code> is specified)</p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def ndscatter(samples: np.ndarray, labels: list[str] = None, tick_fmts: list[str] = None,\n              plot1d: Literal['kde', 'hist'] = None, plot2d: Literal['scatter', 'kde', 'hist', 'hex'] = 'scatter',\n              cmap='viridis', bins=20, cmin=0, z: np.ndarray = None, cb_label=None, cb_norm='linear',\n              subplot_size=3, cov_overlay=None):\n    \"\"\"Triangle scatter plots of n-dimensional samples.\n\n    !!! Warning\n        Best for `dim &lt; 10`. You can shrink the `subplot_size` to assist graphics loading time.\n\n    :param samples: `(N, dim)` samples to plot\n    :param labels: list of axis labels of length `dim`\n    :param tick_fmts: list of str.format() specifiers for ticks, e.g `['{x: ^10.2f}', ...]`, of length `dim`\n    :param plot1d: 'hist' or 'kde' for 1d marginals, defaults to plot2d if None\n    :param plot2d: 'hist' for 2d hist plot, 'kde' for kernel density estimation, 'hex', or 'scatter' (default)\n    :param cmap: the matplotlib string specifier of a colormap\n    :param bins: number of bins in each dimension for histogram marginals\n    :param cmin: the minimum bin count below which the bins are not displayed\n    :param z: `(N,)` a performance metric corresponding to `samples`, used to color code the scatter plot if provided\n    :param cb_label: label for color bar (if `z` is provided)\n    :param cb_norm: `str` or `plt.colors.Normalize`, normalization method for plotting `z` on scatter plot\n    :param subplot_size: size in inches of a single 2d marginal subplot\n    :param cov_overlay: `(ndim, ndim)` a covariance matrix to overlay as a Gaussian kde over the samples\n    :returns fig, axs: the `plt` Figure and Axes objects, (returns an additional `cb_fig, cb_ax` if `z` is specified)\n    \"\"\"\n    N, dim = samples.shape\n    x_min = np.min(samples, axis=0)\n    x_max = np.max(samples, axis=0)\n    show_colorbar = z is not None\n    if labels is None:\n        labels = [f\"x{i}\" for i in range(dim)]\n    if z is None:\n        z = plt.get_cmap(cmap)([0])\n    if cb_label is None:\n        cb_label = 'Performance metric'\n\n    def tick_format_func(value, pos):\n        if np.isclose(value, 0):\n            return f'{value:.2f}'\n        if abs(value) &gt; 1000:\n            return f'{value:.2E}'\n        if abs(value) &gt; 100:\n            return f'{int(value):d}'\n        if abs(value) &gt; 1:\n            return f'{value:.2f}'\n        if abs(value) &gt; 0.01:\n            return f'{value:.4f}'\n        if abs(value) &lt; 0.01:\n            return f'{value:.2E}'\n    default_ticks = FuncFormatter(tick_format_func)\n    # if tick_fmts is None:\n    #     tick_fmts = ['{x:.2G}' for i in range(dim)]\n\n    # Set up triangle plot formatting\n    fig, axs = plt.subplots(dim, dim, sharex='col', sharey='row')\n    for i in range(dim):\n        for j in range(dim):\n            ax = axs[i, j]\n            if i == j:                      # 1d marginals on diagonal\n                # ax.get_shared_y_axes().remove(ax)\n                ax._shared_axes['y'].remove(ax)\n                ax.spines['top'].set_visible(False)\n                ax.spines['right'].set_visible(False)\n                ax.spines['left'].set_visible(False)\n                if i == 0:\n                    ax.get_yaxis().set_ticks([])\n            if j &gt; i:                       # Clear the upper triangle\n                ax.axis('off')\n            if i == dim - 1:                # Bottom row\n                ax.set_xlabel(labels[j])\n                ax.xaxis.set_major_locator(AutoLocator())\n                formatter = StrMethodFormatter(tick_fmts[j]) if tick_fmts is not None else default_ticks\n                ax.xaxis.set_major_formatter(formatter)\n            if j == 0 and i &gt; 0:            # Left column\n                ax.set_ylabel(labels[i])\n                ax.yaxis.set_major_locator(AutoLocator())\n                formatter = StrMethodFormatter(tick_fmts[i]) if tick_fmts is not None else default_ticks\n                ax.yaxis.set_major_formatter(formatter)\n\n    if cov_overlay is not None:\n        x_overlay = normal_sample(np.mean(samples, axis=0), cov_overlay, 5000)\n\n    # Plot marginals\n    for i in range(dim):\n        for j in range(dim):\n            ax = axs[i, j]\n            if i == j:                      # 1d marginals (on diagonal)\n                c = plt.get_cmap(cmap)(0)\n                plot = plot1d if plot1d is not None else plot2d\n                if plot == 'kde':\n                    kernel = st.gaussian_kde(samples[:, i])\n                    x = np.linspace(x_min[i], x_max[i], 500)\n                    ax.fill_between(x, y1=kernel(x), y2=0, lw=0, alpha=0.3, facecolor=c)\n                    ax.plot(x, kernel(x), ls='-', c=c, lw=1.5)\n                else:\n                    ax.hist(samples[:, i], edgecolor='black', color=c, density=True, alpha=0.5,\n                            linewidth=1.2, bins=bins)\n                if cov_overlay is not None:\n                    kernel = st.gaussian_kde(x_overlay[:, i])\n                    x = np.linspace(x_min[i], x_max[i], 500)\n                    ax.fill_between(x, y1=kernel(x), y2=0, lw=0, alpha=0.5, facecolor=[0.5, 0.5, 0.5])\n                    ax.plot(x, kernel(x), ls='-', c='k', lw=1.5, alpha=0.5)\n                bottom, top = ax.get_ylim()\n                ax.set_ylim([0, top])\n            if j &lt; i:                       # 2d marginals (lower triangle)\n                ax.set_xlim([x_min[j], x_max[j]])\n                ax.set_ylim([x_min[i], x_max[i]])\n                if plot2d == 'scatter':\n                    sc = ax.scatter(samples[:, j], samples[:, i], s=1.5, c=z, cmap=cmap, norm=cb_norm)\n                elif plot2d == 'hist':\n                    ax.hist2d(samples[:, j], samples[:, i], bins=bins, cmap=cmap, cmin=cmin)\n                elif plot2d == 'kde':\n                    kernel = st.gaussian_kde(samples[:, [j, i]].T)\n                    xg, yg = np.meshgrid(np.linspace(x_min[j], x_max[j], 40), np.linspace(x_min[i], x_max[i], 40))\n                    x = np.vstack([xg.ravel(), yg.ravel()])\n                    zg = np.reshape(kernel(x), xg.shape)\n                    cs = ax.contourf(xg, yg, zg, 5, cmap=cmap, alpha=0.9, extend='both')\n                    cs.cmap.set_under('white')\n                    cs.changed()\n                    ax.contour(xg, yg, zg, 5, colors=[(0.5, 0.5, 0.5)], linewidths=1.2)\n                elif plot2d == 'hex':\n                    ax.hexbin(samples[:, j], samples[:, i], gridsize=bins, cmap=cmap, mincnt=cmin)\n                else:\n                    raise NotImplementedError('This plot type is not known. plot2d=[\"hist\", \"kde\", \"scatter\"]')\n\n                if cov_overlay is not None:\n                    kernel = st.gaussian_kde(x_overlay[:, [j, i]].T)\n                    xg, yg = np.meshgrid(np.linspace(x_min[j], x_max[j], 40), np.linspace(x_min[i], x_max[i], 40))\n                    x = np.vstack([xg.ravel(), yg.ravel()])\n                    zg = np.reshape(kernel(x), xg.shape)\n                    ax.contourf(xg, yg, zg, 4, cmap='Greys', alpha=0.4)\n                    ax.contour(xg, yg, zg, 4, colors='k', linewidths=1.5, alpha=0.6)\n\n    fig.set_size_inches(subplot_size * dim, subplot_size * dim)\n    fig.tight_layout()\n\n    # Plot colorbar in standalone figure\n    if show_colorbar and plot2d == 'scatter':\n        cb_fig, cb_ax = plt.subplots(figsize=(1.5, 6))\n        cb_fig.subplots_adjust(right=0.7)\n        cb_fig.colorbar(sc, cax=cb_ax, orientation='vertical', label=cb_label)\n        cb_fig.tight_layout()\n        return fig, axs, cb_fig, cb_ax\n\n    return fig, axs\n</code></pre>"},{"location":"reference/plots/#uqtils.plots.plot_slice","title":"<code>plot_slice(funs, bds, x0=None, x_idx=None, y_idx=None, N=50, random_walk=False, xlabels=None, ylabels=None, cmap='viridis', fun_labels=None)</code>","text":"<p>Helper function to plot 1d slices of a function(s) over inputs.</p> PARAMETER DESCRIPTION <code>funs</code> <p>function callable as <code>y=f(x)</code>, with <code>x</code> as <code>(..., xdim)</code> and <code>y</code> as <code>(..., ydim)</code>, can also be a list of functions to evaluate and plot together.</p> <p> </p> <code>bds</code> <p>list of tuples of <code>(min, max)</code> specifying the bounds of the inputs</p> <p> TYPE: <code>list[tuple]</code> </p> <code>x0</code> <p>the default values for all inputs; defaults to middle of <code>bds</code></p> <p> TYPE: <code>Array</code> DEFAULT: <code>None</code> </p> <code>x_idx</code> <p>list of input indices to take 1d slices of</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>y_idx</code> <p>list of output indices to plot 1d slices of</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>N</code> <p>the number of points to take in each 1d slice</p> <p> TYPE: <code>int</code> DEFAULT: <code>50</code> </p> <code>random_walk</code> <p>whether to slice in a random d-dimensional direction or hold all params const while slicing</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>xlabels</code> <p>list of labels for the inputs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>ylabels</code> <p>list of labels for the outputs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>cmap</code> <p>the name of the matplotlib colormap to use</p> <p> DEFAULT: <code>'viridis'</code> </p> <code>fun_labels</code> <p>the legend labels if plotting multiple functions on each plot</p> <p> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <p><code>fig, ax</code> with <code>num_inputs</code> by <code>num_outputs</code> subplots</p> Source code in <code>src/uqtils/plots.py</code> <pre><code>def plot_slice(funs, bds: list[tuple], x0: Array = None, x_idx: list[int] = None,\n               y_idx: list[int] = None, N: int = 50, random_walk: bool = False, xlabels: list[str] = None,\n               ylabels: list[str] = None, cmap='viridis', fun_labels=None):\n    \"\"\"Helper function to plot 1d slices of a function(s) over inputs.\n\n    :param funs: function callable as `y=f(x)`, with `x` as `(..., xdim)` and `y` as `(..., ydim)`, can also be a list\n                of functions to evaluate and plot together.\n    :param bds: list of tuples of `(min, max)` specifying the bounds of the inputs\n    :param x0: the default values for all inputs; defaults to middle of `bds`\n    :param x_idx: list of input indices to take 1d slices of\n    :param y_idx: list of output indices to plot 1d slices of\n    :param N: the number of points to take in each 1d slice\n    :param random_walk: whether to slice in a random d-dimensional direction or hold all params const while slicing\n    :param xlabels: list of labels for the inputs\n    :param ylabels: list of labels for the outputs\n    :param cmap: the name of the matplotlib colormap to use\n    :param fun_labels: the legend labels if plotting multiple functions on each plot\n    :returns: `fig, ax` with `num_inputs` by `num_outputs` subplots\n    \"\"\"\n    funs = funs if isinstance(funs, list) else [funs]\n    x_idx = list(np.arange(0, min(3, len(bds)))) if x_idx is None else x_idx\n    y_idx = [0] if y_idx is None else y_idx\n    xlabels = [f'x{i}' for i in range(len(x_idx))] if xlabels is None else xlabels\n    ylabels = [f'QoI {i}' for i in range(len(y_idx))] if ylabels is None else ylabels\n    fun_labels = [f'fun {i}' for i in range(len(funs))] if fun_labels is None else fun_labels\n    x0 = [(b[0] + b[1]) / 2 for b in bds] if x0 is None else x0\n    x0 = np.atleast_1d(x0)\n    xdim = x0.shape[0]\n    lb = np.atleast_1d([b[0] for b in bds])\n    ub = np.atleast_1d([b[1] for b in bds])\n    cmap = plt.get_cmap(cmap)\n\n    # Construct sliced inputs\n    xs = np.zeros((N, len(x_idx), xdim))\n    for i in range(len(x_idx)):\n        if random_walk:\n            # Make a random straight-line walk across d-cube\n            r0 = np.random.rand(xdim) * (ub - lb) + lb\n            r0[x_idx[i]] = lb[x_idx[i]]                     # Start slice at this lower bound\n            rf = np.random.rand(xdim) * (ub - lb) + lb\n            rf[x_idx[i]] = ub[x_idx[i]]                     # Slice up to this upper bound\n            xs[0, i, :] = r0\n            for k in range(1, N):\n                xs[k, i, :] = xs[k-1, i, :] + (rf-r0)/(N-1)\n        else:\n            # Otherwise, only slice one variable\n            for j in range(xdim):\n                if j == x_idx[i]:\n                    xs[:, i, j] = np.linspace(lb[x_idx[i]], ub[x_idx[i]], N)\n                else:\n                    xs[:, i, j] = x0[j]\n\n    # Compute function values and show ydim by xdim grid of subplots\n    ys = []\n    for func in funs:\n        y = func(xs)\n        if y.shape == (N, len(x_idx)):\n            y = y[..., np.newaxis]\n        ys.append(y)\n    c_intervals = np.linspace(0, 1, len(ys))\n\n    fig, axs = plt.subplots(len(y_idx), len(x_idx), sharex='col', sharey='row')\n    for i in range(len(y_idx)):\n        for j in range(len(x_idx)):\n            if len(y_idx) == 1:\n                ax = axs if len(x_idx) == 1 else axs[j]\n            elif len(x_idx) == 1:\n                ax = axs if len(y_idx) == 1 else axs[i]\n            else:\n                ax = axs[i, j]\n            x = xs[:, j, x_idx[j]]\n            for k in range(len(ys)):\n                y = ys[k][:, j, y_idx[i]]\n                ax.plot(x, y, ls='-', color=cmap(c_intervals[k]), label=fun_labels[k])\n            ylabel = ylabels[i] if j == 0 else ''\n            xlabel = xlabels[j] if i == len(y_idx) - 1 else ''\n            legend = (i == 0 and j == len(x_idx) - 1 and len(ys) &gt; 1)\n            ax_default(ax, xlabel, ylabel, legend=legend)\n    fig.set_size_inches(3 * len(x_idx), 3 * len(y_idx))\n    fig.tight_layout()\n\n    return fig, axs\n</code></pre>"},{"location":"reference/sobol/","title":"sobol","text":""},{"location":"reference/sobol/#uqtils.sobol","title":"<code>uqtils.sobol</code>","text":"<p>Module for Sobol' sensitivity analysis.</p> <p>Includes:</p> <ul> <li><code>sobol_sa</code> - function for global sensitivity analysis</li> </ul>"},{"location":"reference/sobol/#uqtils.sobol.ishigami","title":"<code>ishigami(x, a=7.0, b=0.1)</code>","text":"<p>For testing Sobol indices: Ishigami function</p> Source code in <code>src/uqtils/sobol.py</code> <pre><code>def ishigami(x, a=7.0, b=0.1):\n    \"\"\"For testing Sobol indices: [Ishigami function](https://doi.org/10.1109/ISUMA.1990.151285)\"\"\"\n    return {'y': np.sin(x[..., 0:1]) + a*np.sin(x[..., 1:2])**2 + b*(x[..., 2:3]**4)*np.sin(x[..., 0:1])}\n</code></pre>"},{"location":"reference/sobol/#uqtils.sobol.sobol_sa","title":"<code>sobol_sa(model, sampler, num_samples, qoi_idx=None, qoi_labels=None, param_labels=None, plot=False, verbose=True, cmap='viridis', compute_s2=False)</code>","text":"<p>Perform a global Sobol' sensitivity analysis.</p> PARAMETER DESCRIPTION <code>model</code> <p>callable as <code>y=model(x)</code>, with <code>y=(..., ydim)</code>, <code>x=(..., xdim)</code></p> <p> </p> <code>sampler</code> <p>callable as <code>x=sampler(shape)</code>, with <code>x=(*shape, xdim)</code></p> <p> </p> <code>num_samples</code> <p>number of samples</p> <p> TYPE: <code>int</code> </p> <code>qoi_idx</code> <p>list of indices of model output to report results for</p> <p> TYPE: <code>list[int]</code> DEFAULT: <code>None</code> </p> <code>qoi_labels</code> <p>list of labels for plotting QoIs</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>param_labels</code> <p>list of labels for plotting input parameters</p> <p> TYPE: <code>list[str]</code> DEFAULT: <code>None</code> </p> <code>plot</code> <p>whether to plot bar/pie charts</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>verbose</code> <p>whether to print <code>S1/ST/S2</code> results to the console</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>cmap</code> <p><code>str</code> specifier of <code>plt.colormap</code> for bar/pie charts</p> <p> TYPE: <code>str</code> DEFAULT: <code>'viridis'</code> </p> <code>compute_s2</code> <p>whether to compute the second order indices</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <p><code>S1</code>, <code>[S2]</code>, <code>ST</code>, the first, second, and total order Sobol' indices</p> Source code in <code>src/uqtils/sobol.py</code> <pre><code>def sobol_sa(model, sampler, num_samples: int, qoi_idx: list[int] = None, qoi_labels: list[str] = None,\n             param_labels: list[str] = None, plot: bool = False, verbose: bool = True, cmap: str = 'viridis',\n             compute_s2: bool = False):\n    \"\"\"Perform a global Sobol' sensitivity analysis.\n\n    :param model: callable as `y=model(x)`, with `y=(..., ydim)`, `x=(..., xdim)`\n    :param sampler: callable as `x=sampler(shape)`, with `x=(*shape, xdim)`\n    :param num_samples: number of samples\n    :param qoi_idx: list of indices of model output to report results for\n    :param qoi_labels: list of labels for plotting QoIs\n    :param param_labels: list of labels for plotting input parameters\n    :param plot: whether to plot bar/pie charts\n    :param verbose: whether to print `S1/ST/S2` results to the console\n    :param cmap: `str` specifier of `plt.colormap` for bar/pie charts\n    :param compute_s2: whether to compute the second order indices\n    :return: `S1`, `[S2]`, `ST`, the first, second, and total order Sobol' indices\n    \"\"\"\n    # Get sample matrices (N, xdim)\n    A = sampler((num_samples,))\n    B = sampler((num_samples,))\n    xdim = A.shape[-1]\n    AB = np.tile(np.expand_dims(A, axis=-2), (1, xdim, 1))\n    BA = np.tile(np.expand_dims(B, axis=-2), (1, xdim, 1))\n    for i in range(xdim):\n        AB[:, i, i] = B[:, i]\n        BA[:, i, i] = A[:, i]\n\n    # Evaluate the model; (xdim+2)*N evaluations required\n    fA = model(A)       # (N, ydim)\n    fB = model(B)       # (N, ydim)\n    fAB = model(AB)     # (N, xdim, ydim)\n    fBA = model(BA)     # (N, xdim, ydim)\n    ydim = fA.shape[-1]\n\n    # Normalize model outputs to N(0, 1) for better stability\n    Y = np.concatenate((fA, fB, fAB.reshape((-1, ydim)), fBA.reshape((-1, ydim))), axis=0)\n    mu, std = np.mean(Y, axis=0), np.std(Y, axis=0)\n    fA = (fA - mu) / std\n    fB = (fB - mu) / std\n    fAB = (fAB - mu) / std\n    fBA = (fBA - mu) / std\n\n    # Compute sensitivity indices\n    vY = np.var(np.concatenate((fA, fB), axis=0), axis=0)   # (ydim,)\n    fA = np.expand_dims(fA, axis=-2)                        # (N, 1, ydim)\n    fB = np.expand_dims(fB, axis=-2)                        # (N, 1, ydim)\n    S1 = fB * (fAB - fA) / vY                               # (N, xdim, ydim)\n    ST = 0.5 * (fA - fAB)**2 / vY                           # (N, xdim, ydim)\n\n    # Second-order indices\n    if compute_s2:\n        Vij = np.expand_dims(fBA, axis=2) * np.expand_dims(fAB, axis=1) - \\\n              np.expand_dims(fA, axis=1) * np.expand_dims(fB, axis=1)   # (N, xdim, xdim, ydim)\n        si = fB * (fAB - fA)\n        Vi = np.expand_dims(si, axis=2)\n        Vj = np.expand_dims(si, axis=1)\n        S2 = (Vij - Vi - Vj) / vY                                       # (N, xdim, xdim, ydim)\n        S2_est = np.mean(S2, axis=0)\n        S2_se = np.sqrt(np.var(S2, axis=0) / num_samples)\n\n    # Get mean values and MC error\n    S1_est = np.mean(S1, axis=0)\n    S1_se = np.sqrt(np.var(S1, axis=0) / num_samples)\n    ST_est = np.mean(ST, axis=0)\n    ST_se = np.sqrt(np.var(ST, axis=0) / num_samples)\n\n    # Set defaults for qoi indices/labels\n    if qoi_idx is None:\n        qoi_idx = list(np.arange(ydim))\n    if qoi_labels is None:\n        qoi_labels = [f'QoI {i}' for i in range(len(qoi_idx))]\n    if param_labels is None:\n        param_labels = [f'x{i}' for i in range(xdim)]\n\n    # Print results\n    if verbose:\n        print(f'{\"QoI\":&gt;10} {\"Param\":&gt;10} {\"S1_mean\":&gt;10} {\"S1_err\":&gt;10} {\"ST_mean\":&gt;10} {\"ST_err\":&gt;10}')\n        for i in range(len(qoi_idx)):\n            for j in range(xdim):\n                q = qoi_idx[i]\n                print(f'{qoi_labels[i]:&gt;10} {param_labels[j]:&gt;10} {S1_est[j, q]: 10.3f} {S1_se[j, q]: 10.3f} '\n                      f'{ST_est[j, q]: 10.3f} {ST_se[j, q]: 10.3f}')\n\n        if compute_s2:\n            print(f'\\n{\"QoI\":&gt;10} {\"2nd-order\":&gt;20} {\"S2_mean\":&gt;10} {\"S2_err\":&gt;10}')\n            for i in range(len(qoi_idx)):\n                for j in range(xdim):\n                    for k in range(j+1, xdim):\n                        q = qoi_idx[i]\n                        print(f'{qoi_labels[i]:&gt;10} {\"(\"+param_labels[j]+\", \"+param_labels[k]+\")\":&gt;20} '\n                              f'{S2_est[j, k, q]: 10.3f} {S2_se[j, k, q]: 10.3f}')\n\n        S1_total = np.sum(S1_est, axis=0)       # (ydim,)\n        S2_total = np.zeros((ydim,))            # (ydim,)\n        if compute_s2:\n            for i in range(xdim):\n                for j in range(i+1, xdim):\n                    S2_total += S2_est[i, j, :]     # sum the upper diagonal\n        print(f'\\n{\"QoI\":&gt;10} {\"S1 total\":&gt;10} {\"S2 total\":&gt;10} {\"Higher order\":&gt;15}')\n        for i in range(len(qoi_idx)):\n            q = qoi_idx[i]\n            print(f'{qoi_labels[i]:&gt;10} {S1_total[q]: 10.3f} {S2_total[q]: 10.3f} '\n                  f'{1 - S1_total[q] - S2_total[q]: 15.3f}')\n\n    if plot:\n        # Plot bar chart of S1, ST\n        c = plt.get_cmap(cmap)\n        fig, axs = plt.subplots(1, len(qoi_idx))\n        for i in range(len(qoi_idx)):\n            ax = axs[i] if len(qoi_idx) &gt; 1 else axs\n            q = qoi_idx[i]\n            z = st.norm.ppf(1 - (1-0.95)/2)  # get z-score from N(0,1), assuming CLT at n&gt;30\n            x = np.arange(xdim)\n            width = 0.2\n            ax.bar(x - width / 2, S1_est[:, q], width, color=c(0.1), yerr=S1_se[:, q] * z,\n                   label=r'$S_1$', capsize=3, linewidth=1, edgecolor=[0, 0, 0])\n            ax.bar(x + width / 2, ST_est[:, q], width, color=c(0.9), yerr=ST_se[:, q] * z,\n                   label=r'$S_{T}$', capsize=3, linewidth=1, edgecolor=[0, 0, 0])\n            ax_default(ax, \"Model parameters\", \"Sobol' index\", legend=True)\n            ax.set_xticks(x, param_labels)\n            ax.set_ylim(bottom=0)\n            ax.set_title(qoi_labels[i])\n        fig.set_size_inches(4*len(qoi_idx), 4)\n        fig.tight_layout()\n        bar_chart = (fig, axs)\n\n        # Plot pie chart of S1, S2, higher-order\n        fig, axs = plt.subplots(1, len(qoi_idx))\n        for i in range(len(qoi_idx)):\n            ax = axs[i] if len(qoi_idx) &gt; 1 else axs\n            q = qoi_idx[i]\n            values = []\n            labels = []\n            s12_other = 0\n            thresh = 0.05    # Only show indices with &gt; 5% effect\n            for j in range(xdim):\n                if S1_est[j, q] &gt; thresh:\n                    values.append(S1_est[j, q])\n                    labels.append(param_labels[j])\n                else:\n                    s12_other += max(S1_est[j, q], 0)\n\n            if compute_s2:\n                for j in range(xdim):\n                    for k in range(j+1, xdim):\n                        if S2_est[j, k, q] &gt; thresh:\n                            values.append(S2_est[j, k, q])\n                            labels.append(\"(\"+param_labels[j]+\", \"+param_labels[k]+\")\")\n                        else:\n                            s12_other += max(S2_est[j, k, q], 0)\n\n            values.append(max(s12_other, 0))\n            labels.append(r'Other $S_1$, $S_2$')\n            s_higher = max(1 - np.sum(values), 0)\n            values.append(s_higher)\n            labels.append(r'Higher order')\n\n            # Adjust labels to show percents, sort by value, and threshold small values for plotting\n            labels = [f\"{label}, {100*values[i]:.1f}%\" if values[i] &gt; thresh else\n                      f\"{label}, &lt;{max(0.5, round(100*values[i]))}%\" for i, label in enumerate(labels)]\n            values = [val if val &gt; thresh else max(0.02, val) for val in values]\n            labels, values = list(zip(*sorted(zip(labels, values), reverse=True, key=lambda ele: ele[1])))\n\n            # Generate pie chart\n            colors = c(np.linspace(0, 1, len(values)-2))\n            gray_idx = [idx for idx, label in enumerate(labels) if label.startswith('Higher') or\n                        label.startswith('Other')]\n            pie_colors = np.empty((len(values), 4))\n            c_idx = 0\n            for idx in range(len(values)):\n                if idx in gray_idx:\n                    pie_colors[idx, :] = [0.7, 0.7, 0.7, 1]\n                else:\n                    pie_colors[idx, :] = colors[c_idx, :]\n                    c_idx += 1\n            radius = 2\n            wedges, label_boxes = ax.pie(values, colors=pie_colors, radius=radius, startangle=270,\n                                         shadow=True, counterclock=False, frame=True,\n                                         wedgeprops=dict(linewidth=1.5, width=0.6*radius, edgecolor='w'),\n                                         textprops={'color': [0, 0, 0, 1], 'fontsize': 10, 'family': 'serif'})\n            kw = dict(arrowprops=dict(arrowstyle=\"-\"), zorder=0, va=\"center\", fontsize=9, family='serif',\n                      bbox=dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0))\n\n            # Put annotations with arrows to each wedge (coordinate system is relative to center of pie)\n            for j, wed in enumerate(wedges):\n                ang = (wed.theta2 - wed.theta1) / 2. + wed.theta1\n                x = radius * np.cos(np.deg2rad(ang))\n                y = radius * np.sin(np.deg2rad(ang))\n                ax.scatter(x, y, s=10, c='k')\n                kw[\"horizontalalignment\"] = \"right\" if int(np.sign(x)) == -1 else \"left\"\n                kw[\"arrowprops\"].update({\"connectionstyle\": f\"angle,angleA=0,angleB={ang}\"})\n                y_offset = 0.2 if j == len(labels) - 1 else 0\n                ax.annotate(labels[j], xy=(x, y), xytext=((radius+0.2)*np.sign(x), 1.3*y - y_offset), **kw)\n            ax.set(aspect=\"equal\")\n            ax.spines['top'].set_visible(False)\n            ax.spines['right'].set_visible(False)\n            ax.spines['left'].set_visible(False)\n            ax.spines['bottom'].set_visible(False)\n            ax.get_yaxis().set_ticks([])\n            ax.get_xaxis().set_ticks([])\n            ax.set_title(qoi_labels[i])\n        fig.set_size_inches(3*radius*len(qoi_idx), 2.5*radius)\n        fig.tight_layout()\n        fig.subplots_adjust(left=0.15, right=0.75)\n        pie_chart = (fig, axs)\n\n    if compute_s2:\n        ret = (S1, S2, ST)\n    else:\n        ret = (S1, ST)\n    if plot:\n        ret = ret + (bar_chart, pie_chart)\n    return ret\n</code></pre>"}]}